{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d78fd1b52ad941d09393613dd4983b22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7096cff3dde24dc5825afc0b1913cc4d",
              "IPY_MODEL_64ef1a5a0f834dc48d35d8cf6f59305e",
              "IPY_MODEL_37d0f903120a41c39da61d407ea108e2"
            ],
            "layout": "IPY_MODEL_b7e3917cba2a44b2b4f892d20da8b816"
          }
        },
        "7096cff3dde24dc5825afc0b1913cc4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9c450a1cbc324473beeaeb764096f01d",
            "placeholder": "​",
            "style": "IPY_MODEL_8b531ab9374c4917a6362e55c6eb1364",
            "value": "Map: 100%"
          }
        },
        "64ef1a5a0f834dc48d35d8cf6f59305e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f0e90aaab0bd46f3aa2ddeae19262cdc",
            "max": 15011,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_24e1a1bb87c04aa694adc5c6a3f08c24",
            "value": 15011
          }
        },
        "37d0f903120a41c39da61d407ea108e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b47f6362da744a08831433a42bdf4a25",
            "placeholder": "​",
            "style": "IPY_MODEL_c4f4fbd10c484e7b8cdfe2e59564ae5c",
            "value": " 15011/15011 [00:14&lt;00:00, 651.72 examples/s]"
          }
        },
        "b7e3917cba2a44b2b4f892d20da8b816": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9c450a1cbc324473beeaeb764096f01d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b531ab9374c4917a6362e55c6eb1364": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f0e90aaab0bd46f3aa2ddeae19262cdc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "24e1a1bb87c04aa694adc5c6a3f08c24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b47f6362da744a08831433a42bdf4a25": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c4f4fbd10c484e7b8cdfe2e59564ae5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4cba8e57c195436084fce969c4e64d76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9845c6f6317242ab92dc9f2186afb05b",
              "IPY_MODEL_1dbfa08cc6ca461e9eb6a043dafaa6ba",
              "IPY_MODEL_c0b27cf67e7d47059514dd02ea98b9c4"
            ],
            "layout": "IPY_MODEL_3a633e7619af4e8f9004b3a0952f1341"
          }
        },
        "9845c6f6317242ab92dc9f2186afb05b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9ba0abe8f55947718f312a6921d93bbc",
            "placeholder": "​",
            "style": "IPY_MODEL_6e02e28a1e46454facae48935f745ba3",
            "value": "Map: 100%"
          }
        },
        "1dbfa08cc6ca461e9eb6a043dafaa6ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7d09f09bef414e82970ab9a49fe1ee6c",
            "max": 15011,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9ae51712ec1a4bf7ab7678f61c719b7d",
            "value": 15011
          }
        },
        "c0b27cf67e7d47059514dd02ea98b9c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f0fcea8460db47c1bfc4da4d4bd8dd3a",
            "placeholder": "​",
            "style": "IPY_MODEL_9813e8d377a54fb590af6ce92585bec0",
            "value": " 15011/15011 [00:18&lt;00:00, 1068.70 examples/s]"
          }
        },
        "3a633e7619af4e8f9004b3a0952f1341": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ba0abe8f55947718f312a6921d93bbc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e02e28a1e46454facae48935f745ba3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7d09f09bef414e82970ab9a49fe1ee6c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ae51712ec1a4bf7ab7678f61c719b7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f0fcea8460db47c1bfc4da4d4bd8dd3a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9813e8d377a54fb590af6ce92585bec0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0ae7696ec7fd485d9526de8fbff14415": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a9eeb83248d246e187fa7276d6531b42",
              "IPY_MODEL_e93347b3c0be4b2ea4df998c735b6068",
              "IPY_MODEL_fddcc20dc3a74922be243246852b1e8d"
            ],
            "layout": "IPY_MODEL_14d918da1020481e8a69883f51b0535f"
          }
        },
        "a9eeb83248d246e187fa7276d6531b42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b5dd30ae56f4486788ad8493f23db20b",
            "placeholder": "​",
            "style": "IPY_MODEL_237e3faf93c14f2884ae06ff70c486db",
            "value": "Saving the dataset (1/1 shards): 100%"
          }
        },
        "e93347b3c0be4b2ea4df998c735b6068": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_46955ff233484a8db9d3de8641b93fc5",
            "max": 1528,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_83f220cffb9f40d2b88222d0c9086028",
            "value": 1528
          }
        },
        "fddcc20dc3a74922be243246852b1e8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_298503123eb74e2dacc22269103299b2",
            "placeholder": "​",
            "style": "IPY_MODEL_0c192f7e784f4b63b56484c1d9033028",
            "value": " 1528/1528 [00:00&lt;00:00, 2888.59 examples/s]"
          }
        },
        "14d918da1020481e8a69883f51b0535f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b5dd30ae56f4486788ad8493f23db20b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "237e3faf93c14f2884ae06ff70c486db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "46955ff233484a8db9d3de8641b93fc5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "83f220cffb9f40d2b88222d0c9086028": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "298503123eb74e2dacc22269103299b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c192f7e784f4b63b56484c1d9033028": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ebcc1d52b3314656b49843610e931f3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_78d79e58b9c54248a534dbd4375ab07e",
              "IPY_MODEL_dc6ceaa2a8104ee08514a0b95261b2a0",
              "IPY_MODEL_9eeb6276265043b9924f1c5f41e50fc4"
            ],
            "layout": "IPY_MODEL_cc50baffabd14cf3bc0e439377690010"
          }
        },
        "78d79e58b9c54248a534dbd4375ab07e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4bc8c91497024abbbdd34ad3d319092d",
            "placeholder": "​",
            "style": "IPY_MODEL_fe9b94f87729472b80d21ea2b1aea9e7",
            "value": "README.md: "
          }
        },
        "dc6ceaa2a8104ee08514a0b95261b2a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d402554494b5448ea1b7b76e4edf35dc",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_61eeef3980404b5398735e1fd42b04ad",
            "value": 1
          }
        },
        "9eeb6276265043b9924f1c5f41e50fc4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_244fd982358246e39a7710fe5908d9ac",
            "placeholder": "​",
            "style": "IPY_MODEL_05c3c78868df4a1f98b0c0d3bc5cc8b8",
            "value": " 8.20k/? [00:00&lt;00:00, 71.9kB/s]"
          }
        },
        "cc50baffabd14cf3bc0e439377690010": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4bc8c91497024abbbdd34ad3d319092d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe9b94f87729472b80d21ea2b1aea9e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d402554494b5448ea1b7b76e4edf35dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "61eeef3980404b5398735e1fd42b04ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "244fd982358246e39a7710fe5908d9ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "05c3c78868df4a1f98b0c0d3bc5cc8b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "65273ea601314485a2152233cb045711": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2f76b5bc103546f898196f672352ebf0",
              "IPY_MODEL_556ad743bea74a9fb9a481bef6253cb2",
              "IPY_MODEL_ea5fab5899fd4c7f89d636537d6decca"
            ],
            "layout": "IPY_MODEL_9783ee7d81fc40e09b116b99816550fa"
          }
        },
        "2f76b5bc103546f898196f672352ebf0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_758a595e39ef49fba44cb23831fadd9d",
            "placeholder": "​",
            "style": "IPY_MODEL_485a2423972a44c8bf7c14557bd202df",
            "value": "databricks-dolly-15k.jsonl: 100%"
          }
        },
        "556ad743bea74a9fb9a481bef6253cb2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cb5dd1b55103472e9b4025e6fac47121",
            "max": 13085339,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9572d37d9ad545c696eed1a65a8b2304",
            "value": 13085339
          }
        },
        "ea5fab5899fd4c7f89d636537d6decca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2c2e2f3084184d61add7c8d3489fd0ff",
            "placeholder": "​",
            "style": "IPY_MODEL_6e4eabde7b07405b8c9801a3e3b3ccc8",
            "value": " 13.1M/13.1M [00:01&lt;00:00, 15.6MB/s]"
          }
        },
        "9783ee7d81fc40e09b116b99816550fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "758a595e39ef49fba44cb23831fadd9d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "485a2423972a44c8bf7c14557bd202df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cb5dd1b55103472e9b4025e6fac47121": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9572d37d9ad545c696eed1a65a8b2304": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2c2e2f3084184d61add7c8d3489fd0ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e4eabde7b07405b8c9801a3e3b3ccc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8c149dcd952f4c8188ca9885742041cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a5e2342182b9456daf248d546b9a59de",
              "IPY_MODEL_2ef7eed8ffd04fb3b4d04344a75483d6",
              "IPY_MODEL_376bb508bb944986a5e2d6e37914470b"
            ],
            "layout": "IPY_MODEL_f3e6b17561694f068fb562785d1725eb"
          }
        },
        "a5e2342182b9456daf248d546b9a59de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f5ec8c2674c74f8da9ea6cdd2f2f520c",
            "placeholder": "​",
            "style": "IPY_MODEL_24d6fd5aea9d41e996ae2567b975f7ca",
            "value": "Generating train split: 100%"
          }
        },
        "2ef7eed8ffd04fb3b4d04344a75483d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_732164b833be4fc0a307361db777a04a",
            "max": 15011,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_07e6cf1d066f41f4bcad63316c169894",
            "value": 15011
          }
        },
        "376bb508bb944986a5e2d6e37914470b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d1adaeb96f044f0e833d397b75029308",
            "placeholder": "​",
            "style": "IPY_MODEL_33c142fd8a4440da86c6b6134b63fea7",
            "value": " 15011/15011 [00:00&lt;00:00, 28271.50 examples/s]"
          }
        },
        "f3e6b17561694f068fb562785d1725eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f5ec8c2674c74f8da9ea6cdd2f2f520c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "24d6fd5aea9d41e996ae2567b975f7ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "732164b833be4fc0a307361db777a04a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "07e6cf1d066f41f4bcad63316c169894": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d1adaeb96f044f0e833d397b75029308": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "33c142fd8a4440da86c6b6134b63fea7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cfa8f184a89042c89485ae9fda7b6335": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_210b0f5a0c044dd99dd1e3e30c03715c",
              "IPY_MODEL_b0e24bff431b44d3956aa0bdf5dbc9c6",
              "IPY_MODEL_a4ba5e205749471f8762e036529b85a3"
            ],
            "layout": "IPY_MODEL_49321ef8956844679e3aecd19d51f456"
          }
        },
        "210b0f5a0c044dd99dd1e3e30c03715c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2fec05d08a7f4389a629582050c195d2",
            "placeholder": "​",
            "style": "IPY_MODEL_004c5fb584a34695b3f5dcc38cf2d5b6",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "b0e24bff431b44d3956aa0bdf5dbc9c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6860611642b44eb2b42345d7f3e5b78b",
            "max": 967,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_82cad193984e471086557e5bb9600b8f",
            "value": 967
          }
        },
        "a4ba5e205749471f8762e036529b85a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_be4942e5906448a688ca809660c9aa58",
            "placeholder": "​",
            "style": "IPY_MODEL_7b3fb3801d924471a3c40bb4a4c44bf8",
            "value": " 967/967 [00:00&lt;00:00, 19.9kB/s]"
          }
        },
        "49321ef8956844679e3aecd19d51f456": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2fec05d08a7f4389a629582050c195d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "004c5fb584a34695b3f5dcc38cf2d5b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6860611642b44eb2b42345d7f3e5b78b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "82cad193984e471086557e5bb9600b8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "be4942e5906448a688ca809660c9aa58": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7b3fb3801d924471a3c40bb4a4c44bf8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e6e0c0c4393b4864815b11ead123ec09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f9a6f0512cdc4c94bc35bab05a0b8728",
              "IPY_MODEL_52cf53ab38a9491eb8475378759b0b82",
              "IPY_MODEL_5364575a6f8d4d06b9c36e27744bf167"
            ],
            "layout": "IPY_MODEL_bb3b676ef7a54b1ea2ef814a54650c0d"
          }
        },
        "f9a6f0512cdc4c94bc35bab05a0b8728": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3a85abf2f30642448b2f695534e88a69",
            "placeholder": "​",
            "style": "IPY_MODEL_868ac40638014f838a9235c9651fa079",
            "value": "tokenizer.model: 100%"
          }
        },
        "52cf53ab38a9491eb8475378759b0b82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cca46a83513e4ce4af015471d4adcbde",
            "max": 493443,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f7359e7419144948bd6dc7bd8ce18cf7",
            "value": 493443
          }
        },
        "5364575a6f8d4d06b9c36e27744bf167": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_edccc53736474648a5a5f2f740759427",
            "placeholder": "​",
            "style": "IPY_MODEL_cbd04fa270ac4068ac051f2f7298fe79",
            "value": " 493k/493k [00:01&lt;00:00, 491kB/s]"
          }
        },
        "bb3b676ef7a54b1ea2ef814a54650c0d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a85abf2f30642448b2f695534e88a69": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "868ac40638014f838a9235c9651fa079": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cca46a83513e4ce4af015471d4adcbde": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f7359e7419144948bd6dc7bd8ce18cf7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "edccc53736474648a5a5f2f740759427": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cbd04fa270ac4068ac051f2f7298fe79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "02acb5adb8a145c6a6495fbbad4ed083": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_699c1288b5e84fda9fdf3d68517e7ca9",
              "IPY_MODEL_f6ce95aa5fed4beab68f19563a31548e",
              "IPY_MODEL_1dedee3b6ea942fa98176c869122d882"
            ],
            "layout": "IPY_MODEL_e54c4990ca8a4371ac33a5c86ca42a8e"
          }
        },
        "699c1288b5e84fda9fdf3d68517e7ca9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7408cee008eb48b68998c0e24e8eef77",
            "placeholder": "​",
            "style": "IPY_MODEL_3d3096939433492c88fc6feaa9cce0ff",
            "value": "tokenizer.json: "
          }
        },
        "f6ce95aa5fed4beab68f19563a31548e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_42cacfe9db634b6f9bc0638c92d82fdc",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4eb28bc421304b23ab4b98100c749c3e",
            "value": 1
          }
        },
        "1dedee3b6ea942fa98176c869122d882": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_078988439f30499793666c930600909e",
            "placeholder": "​",
            "style": "IPY_MODEL_890b37a1508c40dcaa4679622e2f1f71",
            "value": " 1.80M/? [00:00&lt;00:00, 13.1MB/s]"
          }
        },
        "e54c4990ca8a4371ac33a5c86ca42a8e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7408cee008eb48b68998c0e24e8eef77": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d3096939433492c88fc6feaa9cce0ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "42cacfe9db634b6f9bc0638c92d82fdc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "4eb28bc421304b23ab4b98100c749c3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "078988439f30499793666c930600909e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "890b37a1508c40dcaa4679622e2f1f71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "248077c64ce94da7afbd5f39bf0570ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f65fc63301bf4aa0b4e7ca3ca377aa11",
              "IPY_MODEL_ca51cc25ebfe4ba2911d65159be01273",
              "IPY_MODEL_c5e2ca1a56e0434f906d88d40dd1ea3c"
            ],
            "layout": "IPY_MODEL_1acbaea997ae42bd98f11beb915f8027"
          }
        },
        "f65fc63301bf4aa0b4e7ca3ca377aa11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_88c0336a7ff84176b0e5cbe424f03619",
            "placeholder": "​",
            "style": "IPY_MODEL_aa20e15c0ffc48d2bd90a991430772b3",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "ca51cc25ebfe4ba2911d65159be01273": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1f61dc10ab764b6aae8800353f915407",
            "max": 72,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_efdc7a75e45643919139bbd5f19ce744",
            "value": 72
          }
        },
        "c5e2ca1a56e0434f906d88d40dd1ea3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_38954b15e4824897bcfa9111a689930d",
            "placeholder": "​",
            "style": "IPY_MODEL_313134813e7f4f37b1ab5c7c946410f3",
            "value": " 72.0/72.0 [00:00&lt;00:00, 1.66kB/s]"
          }
        },
        "1acbaea997ae42bd98f11beb915f8027": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "88c0336a7ff84176b0e5cbe424f03619": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa20e15c0ffc48d2bd90a991430772b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1f61dc10ab764b6aae8800353f915407": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "efdc7a75e45643919139bbd5f19ce744": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "38954b15e4824897bcfa9111a689930d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "313134813e7f4f37b1ab5c7c946410f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f12de8b7cde24fc0ab89ab166b805881": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9aae4b5ecb3b4624ab589291ddfefb2c",
              "IPY_MODEL_51ca3196909341df80e97b2f7d73f7b5",
              "IPY_MODEL_ebad3f5e76e941bd8626edc6422ee68f"
            ],
            "layout": "IPY_MODEL_cade512f253647bca8b4c832f05f9b40"
          }
        },
        "9aae4b5ecb3b4624ab589291ddfefb2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f363232eda994c439a72504e29ad50fc",
            "placeholder": "​",
            "style": "IPY_MODEL_c4053ef7718d4ba5ba6b593f164f297e",
            "value": "Map: 100%"
          }
        },
        "51ca3196909341df80e97b2f7d73f7b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cbe00b394b424b3d9e4591847839d246",
            "max": 15011,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2aefa2a7208043c4a7bafef17b1795e6",
            "value": 15011
          }
        },
        "ebad3f5e76e941bd8626edc6422ee68f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_888b538e8d9f45cb97d760cadfebd4f0",
            "placeholder": "​",
            "style": "IPY_MODEL_84ff3a508a03403aabc80d58d6c9663e",
            "value": " 15011/15011 [00:08&lt;00:00, 1578.30 examples/s]"
          }
        },
        "cade512f253647bca8b4c832f05f9b40": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f363232eda994c439a72504e29ad50fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c4053ef7718d4ba5ba6b593f164f297e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cbe00b394b424b3d9e4591847839d246": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2aefa2a7208043c4a7bafef17b1795e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "888b538e8d9f45cb97d760cadfebd4f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "84ff3a508a03403aabc80d58d6c9663e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Fine tune Mixtral-8x7B\n",
        "\n",
        "This is a 7 billion parameter model, you can not compare with ChatGPT 4.5 or Sauna 4 because this model has way less parameters. The reason why we are going to fine tune this model is because it is a lot cheaper, we could also fine tune other open source model that have 100 of billions of parameters but it would cost thousands of dollars.\n",
        "\n",
        "Our model is going to perform exceptionally well through the Fine tune. We are goin to make fine tune a lot cheaper and faster through the next methods:\n",
        "\n",
        "1. Mix precision training\n",
        "2. Quantization\n",
        "3. LoRA\n",
        "\n",
        "For the fine tune we are gonna be using databricks_dolly-15, which contains 15,000 samples manually generated by people at Databricks to train LLM.\n",
        "\n",
        "The learning flow is going to be something like this\n",
        "\n",
        "1. **Download:** the notebook is goign to download the dataset `databricks-dolly-15k` from Hugging Face\n",
        "2. **Get the right format:** we are going to pass the data through format_dolly function, which is going to add some Headers.\n",
        "3. **Upload:** We are goign to upload the data to S3\n",
        "4. **Training:** the script `run_clm.py` is going to download the data from **S3** and give it to the Trainer\n",
        "\n",
        "## The data from HuggingFace\n",
        "The type of data we are going to be download from HuggingFace, `databricks-dolly-15k` it will look like:\n",
        "\n",
        "```python\n",
        "\n",
        "[\n",
        "  {\"instruction\": \"hola\", \"context\" : \"some context in here\",  \"response\": \"mundo\"},      # dataset[0]\n",
        "  {\"instruction\": \"pregunta\", \"context\": \"some context here\",\"response\": \"respuesta\"} # dataset[1]\n",
        "]\n",
        "```"
      ],
      "metadata": {
        "id": "0mmELGRC4D9J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gathering, Chunking, Tokenizing and Uploading our Dataset"
      ],
      "metadata": {
        "id": "vlGfKQXFGLA4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sagemaker Sessions, Regions, and IAM Roles"
      ],
      "metadata": {
        "id": "k5JoX4NsWycQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ls2xtJuTWNQh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb3238ae-2c20-4702-c095-3a79247b933b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/59.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.7/59.7 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.5/52.5 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.1/40.1 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m511.6/511.6 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.3/87.3 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.5/14.5 MB\u001b[0m \u001b[31m77.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.7/47.7 MB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m55.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m204.0/204.0 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m237.2/237.2 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.6/140.6 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.9/114.9 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m100.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m65.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m56.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m223.9/223.9 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.9/294.9 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.4/91.4 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.1/18.1 MB\u001b[0m \u001b[31m93.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.4/17.4 MB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m621.9/621.9 kB\u001b[0m \u001b[31m36.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.2/278.2 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.0/115.0 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.0/85.0 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m160.3/160.3 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m46.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m55.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.8/111.8 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m764.2/764.2 kB\u001b[0m \u001b[31m38.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.5/52.5 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m71.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.7/264.7 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "opentelemetry-exporter-otlp-proto-common 1.37.0 requires opentelemetry-proto==1.37.0, but you have opentelemetry-proto 1.27.0 which is incompatible.\n",
            "ydf 0.13.0 requires protobuf<7.0.0,>=5.29.1, but you have protobuf 4.25.8 which is incompatible.\n",
            "opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-proto==1.37.0, but you have opentelemetry-proto 1.27.0 which is incompatible.\n",
            "grpcio-status 1.71.2 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 4.25.8 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "%pip install --quiet --upgrade transformers datasets sagemaker s3fs\n",
        "# s3fs comunicate with S3 to save our traing data, the output model as well"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sagemaker\n",
        "import boto3 # python SDK for AWS"
      ],
      "metadata": {
        "id": "pTBlS_1tWi89"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "sagemaker.Session(): Es el \"control remoto\". Inicia la conexión entre tu código Python y la infraestructura de AWS. Gestiona las interacciones con S3 y los trabajos de entrenamiento."
      ],
      "metadata": {
        "id": "Vp34W0LUUVjY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sess = sagemaker.Session() # your sagemaker session\n",
        "# the output will be something like\n",
        "# <sagemaker.session.Session as 0x7fe854f4af00>\n",
        "sess"
      ],
      "metadata": {
        "id": "5AAO4gA8XGpd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "outputId": "6991c0b8-67f5-45e8-c35d-aa510b2c45b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "module 'sagemaker' has no attribute 'Session'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3222201901.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msagemaker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# your sagemaker sessio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# the output will be something like\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# <sagemaker.session.Session as 0x7fe854f4af00>\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'sagemaker' has no attribute 'Session'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* get_execution_role(): Es el \"pasaporte\". Este notebook necesita permisos para leer datos de S3 y encender instancias GPU caras. Este rol de IAM (Identity and Access Management) le da permiso para hacerlo. Si este rol no tiene los permisos correctos, el código fallará más adelante al intentar subir datos.\n",
        "\n",
        "* Región (boto_region_name): Es crítico que tu notebook y tu bucket de S3 (donde guardas los datos) estén en la misma zona geográfica (ej. us-east-1). Si no, AWS te cobrará extra por transferencia de datos y el entrenamiento podría fallar."
      ],
      "metadata": {
        "id": "Ms9c_8e9UtDd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# What permisions does our notebook has access to?\n",
        "role = sagemaker.get_execution_role()\n",
        "role # this is not your IAM role\n",
        "# this is the rol of your sagemaker notebook\n",
        "# this tells the notebook what it has access to"
      ],
      "metadata": {
        "id": "Vl7b8_DMXx4f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Where our notebook session is?\n",
        "# the session must be the same with your s3 bucket\n",
        "# Sometimes your training job dont even work if your training data\n",
        "# is not in the same region as your notebook\n",
        "sess.bot_region_name"
      ],
      "metadata": {
        "id": "1-ON6nIDYSSN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Examining Our Dataset from HuggingFace\n",
        "\n",
        "now we are going to load the dolly 15k which is a high quality set of prompt response pairs which has been generated by humans and it is perfect for instruccion fine tuning LLMs.\n",
        "\n",
        "https://huggingface.co/datasets/databricks/databricks-dolly-15k\n",
        "\n",
        "Let's load the data:"
      ],
      "metadata": {
        "id": "l2617PlNaKSK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/Ideas/AI_Engineering_Customizing_LLMs_for_Business_(Fine-Tuning_LLMs_with_QLoRA_&_AWS)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cDT-8UIFcuxV",
        "outputId": "1add9216-f195-4367-81bd-8aab6ca6cc09"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Ideas/AI_Engineering_Customizing_LLMs_for_Business_(Fine-Tuning_LLMs_with_QLoRA_&_AWS)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "from random import randrange\n",
        "\n",
        "dataset = load_dataset('databricks/databricks-dolly-15k', split='train') # we want to look at the train set\n",
        "\n",
        "print(f'Dataset size; {len(dataset)}') # 15011\n",
        "print(dataset[randrange(len(dataset))]) # select a random item from the entire length of the dataset"
      ],
      "metadata": {
        "id": "baRmS1mXaJ92",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168,
          "referenced_widgets": [
            "ebcc1d52b3314656b49843610e931f3c",
            "78d79e58b9c54248a534dbd4375ab07e",
            "dc6ceaa2a8104ee08514a0b95261b2a0",
            "9eeb6276265043b9924f1c5f41e50fc4",
            "cc50baffabd14cf3bc0e439377690010",
            "4bc8c91497024abbbdd34ad3d319092d",
            "fe9b94f87729472b80d21ea2b1aea9e7",
            "d402554494b5448ea1b7b76e4edf35dc",
            "61eeef3980404b5398735e1fd42b04ad",
            "244fd982358246e39a7710fe5908d9ac",
            "05c3c78868df4a1f98b0c0d3bc5cc8b8",
            "65273ea601314485a2152233cb045711",
            "2f76b5bc103546f898196f672352ebf0",
            "556ad743bea74a9fb9a481bef6253cb2",
            "ea5fab5899fd4c7f89d636537d6decca",
            "9783ee7d81fc40e09b116b99816550fa",
            "758a595e39ef49fba44cb23831fadd9d",
            "485a2423972a44c8bf7c14557bd202df",
            "cb5dd1b55103472e9b4025e6fac47121",
            "9572d37d9ad545c696eed1a65a8b2304",
            "2c2e2f3084184d61add7c8d3489fd0ff",
            "6e4eabde7b07405b8c9801a3e3b3ccc8",
            "8c149dcd952f4c8188ca9885742041cf",
            "a5e2342182b9456daf248d546b9a59de",
            "2ef7eed8ffd04fb3b4d04344a75483d6",
            "376bb508bb944986a5e2d6e37914470b",
            "f3e6b17561694f068fb562785d1725eb",
            "f5ec8c2674c74f8da9ea6cdd2f2f520c",
            "24d6fd5aea9d41e996ae2567b975f7ca",
            "732164b833be4fc0a307361db777a04a",
            "07e6cf1d066f41f4bcad63316c169894",
            "d1adaeb96f044f0e833d397b75029308",
            "33c142fd8a4440da86c6b6134b63fea7"
          ]
        },
        "outputId": "6ac37ad7-7ffe-47b2-d323-180a4f4f36b5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ebcc1d52b3314656b49843610e931f3c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "databricks-dolly-15k.jsonl:   0%|          | 0.00/13.1M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "65273ea601314485a2152233cb045711"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/15011 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8c149dcd952f4c8188ca9885742041cf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset size; 15011\n",
            "{'instruction': 'What is a polygon?', 'context': '', 'response': 'A polygon is a form in Geometry.  It is a single dimensional plane made of connecting lines and any number of vertices.  It is a closed chain of connected line segments or edges.  The vertices of the polygon are formed where two edges meet.  Examples of polygons are hexagons, pentagons, and octagons.  Any plane that does not contain edges or vertices is not a polygon.  An example of a non-polygon is a circle.', 'category': 'open_qa'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# this is an object from huggingface library\n",
        "print(type(dataset))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S4SAp3AmKKu-",
        "outputId": "c54e2edc-354c-4b65-88cb-20f95cf9dbf8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'datasets.arrow_dataset.Dataset'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset.features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VYAK51q0KY-F",
        "outputId": "adf43ea2-5df8-4c8c-a6fd-21e73a5043b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'instruction': Value('string'), 'context': Value('string'), 'response': Value('string'), 'category': Value('string')}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now let's use a function to convert our data into tasks prompts\n",
        "def format_dolly(sample):\n",
        "  instruction = f\"### Instruction\\n{sample['instruction']}\"\n",
        "  context = f\"### Context\\n{sample['context']}\" if len(sample['context']) > 0 else None # when we dont have a context we want to provide None and later on we would filter out the Nones\n",
        "  response = f\"### Answer\\n{sample['response']}\"\n",
        "  prompt = \"\\n\\n\".join([i for i in [instruction, context, response] if i is not None])# we only keep those values which are not None\n",
        "  return prompt"
      ],
      "metadata": {
        "id": "Wb0vLQTedsxn"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(format_dolly(dataset[randrange(len(dataset))]))"
      ],
      "metadata": {
        "id": "iS7x9MlSgYDi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64fff07c-2361-4f73-8ef3-a70dfb6d4f5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### Instruction\n",
            "How many awards did the film The Walrus and the Whistleblower win per this entry of information?\n",
            "\n",
            "### Context\n",
            "The Walrus and the Whistleblower is a 2020 Canadian documentary film directed by Nathalie Bibeau. The film profiles Phil Demers, a former employee of Marineland who attempted to blow the whistle on allegedly inhumane treatment of animals at the institution.\n",
            "\n",
            "According to a film industry newsletter, the film was made \"in association with the Documentary Channel, and CBC Docs\". The Documentary Channel's announcement about the film stated that Demers had \"appeared four times on the Joe Rogan show, has testified before the Canadian Senate, and is being sued for $1.5 million for plotting to steal Smooshi, the walrus\".\n",
            "\n",
            "The film premiered as part of the 2020 Hot Docs Canadian International Documentary Festival. Due to the COVID-19 pandemic in Canada it was not screened theatrically, but premiered as part of the festival's online streaming component and aired on CBC Television on May 28 as part of the network's special Hot Docs at Home series of films from the festival.\n",
            "\n",
            "In June 2020, the film was named as the winner of 2020 Rogers Audience Award, alongside the films 9/11 Kids, There's No Place Like This Place, Anyplace, First We Eat and The Forbidden Reel, and as Overall Favourite at Hot Docs. The Audience Award allowed the film to be fast tracked in the Academy Award for Best Documentary Feature category, \"provided it meets all other criteria for eligibility\". Northern Banner, a division of Raven Banner Entertainment, subsequently announced that it had acquired the rights to distribute the film in Canada, probably starting before year end. The US and international distribution rights went to Gravitas Ventures.\n",
            "\n",
            "The film received a nomination for the Donald Brittain Award at the 9th Canadian Screen Awards in 2021.\n",
            "\n",
            "### Answer\n",
            "2.  the 2020 Rogers Audience Award, and the Donald Brittain Award in 2021.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "HuggingFace Authentication with Sagemaker"
      ],
      "metadata": {
        "id": "OLex7aOEl0sH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"HF_TOKEN\"] = \"hf_*************************************\""
      ],
      "metadata": {
        "id": "PqccdtN3tPs-"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenization and Word Embeddings\n",
        "\n",
        "We have to tokenize the inputs then those tokenize inputs get a token ID, and then those token ID get look up on an embedding table.\n",
        "Once we convert this words into words embedding then we can feed them into LLM that can uderstand it."
      ],
      "metadata": {
        "id": "z1jtuqU2jWp5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![](https://raw.githubusercontent.com/sebastianperezv/AI_Engineering_Customizing_LLMs_for_Buisness/refs/heads/main/Images/Tokenization.jpg)"
      ],
      "metadata": {
        "id": "WF2jMKvSaICi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Padding\n",
        "\n",
        "Con Padding (Usando EOS </s> que vale, digamos, 2):\n",
        "\n",
        "\n",
        "[101, 204, 2, 2]    <-- \"Hola mundo\" + Relleno\n",
        "\n",
        "[101, 204, 305, 400] <-- \"Hola mundo cruel hoy\""
      ],
      "metadata": {
        "id": "rYKxev4cPd_k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "model_id = \"mistralai/Mixtral-8x7B-v0.1\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "# Now we can tokenize the inputs\n",
        "# After the tokenization it is going to give us a token ID\n",
        "tokenizer.pad_token = tokenizer.eos_token # pad those sentences which are not long enough\n",
        "# so it is going to be the same as the longer one\n",
        "# It will ensure that each prompt has the same lenght that why we need the padding"
      ],
      "metadata": {
        "id": "kGp0PYh5jYLF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "cfa8f184a89042c89485ae9fda7b6335",
            "210b0f5a0c044dd99dd1e3e30c03715c",
            "b0e24bff431b44d3956aa0bdf5dbc9c6",
            "a4ba5e205749471f8762e036529b85a3",
            "49321ef8956844679e3aecd19d51f456",
            "2fec05d08a7f4389a629582050c195d2",
            "004c5fb584a34695b3f5dcc38cf2d5b6",
            "6860611642b44eb2b42345d7f3e5b78b",
            "82cad193984e471086557e5bb9600b8f",
            "be4942e5906448a688ca809660c9aa58",
            "7b3fb3801d924471a3c40bb4a4c44bf8",
            "e6e0c0c4393b4864815b11ead123ec09",
            "f9a6f0512cdc4c94bc35bab05a0b8728",
            "52cf53ab38a9491eb8475378759b0b82",
            "5364575a6f8d4d06b9c36e27744bf167",
            "bb3b676ef7a54b1ea2ef814a54650c0d",
            "3a85abf2f30642448b2f695534e88a69",
            "868ac40638014f838a9235c9651fa079",
            "cca46a83513e4ce4af015471d4adcbde",
            "f7359e7419144948bd6dc7bd8ce18cf7",
            "edccc53736474648a5a5f2f740759427",
            "cbd04fa270ac4068ac051f2f7298fe79",
            "02acb5adb8a145c6a6495fbbad4ed083",
            "699c1288b5e84fda9fdf3d68517e7ca9",
            "f6ce95aa5fed4beab68f19563a31548e",
            "1dedee3b6ea942fa98176c869122d882",
            "e54c4990ca8a4371ac33a5c86ca42a8e",
            "7408cee008eb48b68998c0e24e8eef77",
            "3d3096939433492c88fc6feaa9cce0ff",
            "42cacfe9db634b6f9bc0638c92d82fdc",
            "4eb28bc421304b23ab4b98100c749c3e",
            "078988439f30499793666c930600909e",
            "890b37a1508c40dcaa4679622e2f1f71",
            "248077c64ce94da7afbd5f39bf0570ab",
            "f65fc63301bf4aa0b4e7ca3ca377aa11",
            "ca51cc25ebfe4ba2911d65159be01273",
            "c5e2ca1a56e0434f906d88d40dd1ea3c",
            "1acbaea997ae42bd98f11beb915f8027",
            "88c0336a7ff84176b0e5cbe424f03619",
            "aa20e15c0ffc48d2bd90a991430772b3",
            "1f61dc10ab764b6aae8800353f915407",
            "efdc7a75e45643919139bbd5f19ce744",
            "38954b15e4824897bcfa9111a689930d",
            "313134813e7f4f37b1ab5c7c946410f3"
          ]
        },
        "outputId": "a97795f6-baf4-4ded-c7b9-a24362f2ccd4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/967 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cfa8f184a89042c89485ae9fda7b6335"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e6e0c0c4393b4864815b11ead123ec09"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "02acb5adb8a145c6a6495fbbad4ed083"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/72.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "248077c64ce94da7afbd5f39bf0570ab"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Applying the Templating Function to our Dataset\n",
        "\n",
        "We are going to delete what we do not need adding to anew key called 'text'"
      ],
      "metadata": {
        "id": "FqhdA6J6wdVh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from random import randint\n",
        "from itertools import chain\n",
        "from functools import partial"
      ],
      "metadata": {
        "id": "2qgKPaGbweTO"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# we are going to create a text column\n",
        "def template_dataset(sample):\n",
        "  # Every sample is gonna have a text key\n",
        "  # and the text key is what actually holds\n",
        "  # all the information\n",
        "  # we create a new key\n",
        "  sample['text'] = f\"{format_dolly(sample)}{tokenizer.eos_token}\" # going to add <s> the model knows when the answer has finished\n",
        "  return sample"
      ],
      "metadata": {
        "id": "DZcz1LqJxw3J"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "template_dataset(dataset[randrange(len(dataset))])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BfqhstVMQLBf",
        "outputId": "9dc0fc61-60f5-4e05-8ac8-b2947d5d6fea"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'instruction': 'road trip to Kerala from Bangalore.',\n",
              " 'context': '',\n",
              " 'response': \"You can plan for a One Week Road trip from Bangalore to Entire Kerala.\\n\\nDay 1: Start early in the morning.First destination Munnar. You can reach Munnar in 10 hours. Stay in a nice hotel facing Tea estate. Relax for the day.\\n\\nDay 2 : Travel Munnar . You can change the hotel for Different view.\\n\\nDay 3 : Start after breakfast for Kochi, It's a port City. Reach Kochi near about 3 hours 30 minutes, visit kochi port beach walk . And stay at night near Marari beach , any sea facing resort(1 hr from Kochi) and \\n\\nDay 4 : Half an hour from Marari beach, go to Alyppe (Alappuzha) , Stay boat house. This is Beautiful!!  Enjoy the Alappuzha Lake ride in your boat.\\n\\nDay 5 : Go to Varkala. Stop for Jatayu earth center , this is outstanding. Varaka has very nice beach shopping and restaurant .\\n\\nDay 6 : Go to Poovar, there any many nice sea facing resort. And do not forget to go for Mangrove tour.\\n\\nDay 7 : You can go to Kanyakumari and back to Bangalore\",\n",
              " 'category': 'creative_writing',\n",
              " 'text': \"### Instruction\\nroad trip to Kerala from Bangalore.\\n\\n### Answer\\nYou can plan for a One Week Road trip from Bangalore to Entire Kerala.\\n\\nDay 1: Start early in the morning.First destination Munnar. You can reach Munnar in 10 hours. Stay in a nice hotel facing Tea estate. Relax for the day.\\n\\nDay 2 : Travel Munnar . You can change the hotel for Different view.\\n\\nDay 3 : Start after breakfast for Kochi, It's a port City. Reach Kochi near about 3 hours 30 minutes, visit kochi port beach walk . And stay at night near Marari beach , any sea facing resort(1 hr from Kochi) and \\n\\nDay 4 : Half an hour from Marari beach, go to Alyppe (Alappuzha) , Stay boat house. This is Beautiful!!  Enjoy the Alappuzha Lake ride in your boat.\\n\\nDay 5 : Go to Varkala. Stop for Jatayu earth center , this is outstanding. Varaka has very nice beach shopping and restaurant .\\n\\nDay 6 : Go to Poovar, there any many nice sea facing resort. And do not forget to go for Mangrove tour.\\n\\nDay 7 : You can go to Kanyakumari and back to Bangalore</s>\"}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.features"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h1_-1vqVvhoo",
        "outputId": "aed2c02b-d051-41ac-b781-23ca9da687ff"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'instruction': Value('string'),\n",
              " 'context': Value('string'),\n",
              " 'response': Value('string'),\n",
              " 'category': Value('string')}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "how do we applied the template_dataset function to the entire dataset. We use map"
      ],
      "metadata": {
        "id": "Mq8ua51czLDA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We just want the text column\n",
        "# we are going to delete all the other features\n",
        "dataset = dataset.map(template_dataset, remove_columns=list(dataset.features))"
      ],
      "metadata": {
        "id": "27khzg-VzDyR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "f12de8b7cde24fc0ab89ab166b805881",
            "9aae4b5ecb3b4624ab589291ddfefb2c",
            "51ca3196909341df80e97b2f7d73f7b5",
            "ebad3f5e76e941bd8626edc6422ee68f",
            "cade512f253647bca8b4c832f05f9b40",
            "f363232eda994c439a72504e29ad50fc",
            "c4053ef7718d4ba5ba6b593f164f297e",
            "cbe00b394b424b3d9e4591847839d246",
            "2aefa2a7208043c4a7bafef17b1795e6",
            "888b538e8d9f45cb97d760cadfebd4f0",
            "84ff3a508a03403aabc80d58d6c9663e"
          ]
        },
        "outputId": "f57a76cb-284f-4fe0-eba9-c9da86f62608"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/15011 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f12de8b7cde24fc0ab89ab166b805881"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.features"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PxnbJu9Dt-GR",
        "outputId": "9c09c40e-e3c7-445f-d111-e6cc0075ad84"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'text': Value('string')}"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7-4pqDFbtzVg",
        "outputId": "4942264e-2b91-4f7f-ee3f-f47e3f1e6c4e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'text': '### Instruction\\nWhich is a species of fish? Tope or Rope\\n\\n### Answer\\nTope</s>'}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# you will be able to see the special toke\n",
        "# the llm now knows that over there we are ending the current sequence\n",
        "print(dataset[randint(0, len(dataset))]['text'])"
      ],
      "metadata": {
        "id": "NYJC5ycSz2OZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "410d53f9-a826-4e28-92f6-acf654477ce9"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### Instruction\n",
            "Why did Georges think that Helene redirected her affections towards Walter Rogers?\n",
            "\n",
            "### Context\n",
            "Papa Chibou (Paul Muni), the elderly caretaker of Musée Pratouchy, a Parisian wax museum, feels a strong kinship with the figures, particularly with that of Napoleon. He spots at the waxworks a romantic young couple, Georges (Russell Gleason), a lawyer, and Helene (Marguerite Churchill), the daughter of a stern judge (Lester Lonergan) who disapproves of his daughter's choice and forbids her to see Georges. Papa Chibou suggests to them that they can still stay in touch, without disobeying her father's directive not to speak with each other, by placing secret personal messages in the pockets of Napoleon's uniform. However, a missing letter and confusion in communication causes Georges to arrive at the mistaken conclusion that Helene has redirected her affections towards a foolish young man (Walter Rogers), who is unworthy of her and excessively preoccupied with his stylish personal appearance and elegant clothing.\n",
            "\n",
            "### Answer\n",
            "A missing letter and confusion in communication caused Georges to arrive at the mistaken conclusion that Helene has redirected her affections towards Walter Rogers (a foolish young man), who is unworthy of her and excessively preoccupied with his stylish personal appearance and elegant clothing.</s>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Attention Masks and Padding"
      ],
      "metadata": {
        "id": "UhLOSginAU7U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reminder dictionary\n",
        "\n",
        "A remainder dictionary is when you cut of the prompts\n",
        "\n",
        "* **input_ids**: this are the token IDs for each word.\n",
        "\n",
        "* **attention_mask**: remember that we want to make sure that each input is consitence, so it has the same lenght, well to do that we need to do padding. And when we pad we say, they must have a fix lenght, but some of them are shorter than the others so we pad them out, that's why there are zeros at the end. So, the attention mask, it tells the model the actual tokens by one, and uses zero for padding, so the modelwould only pay attention to the ones.\n",
        "\n",
        "* **token_type_ids**: Mixtrat does not have token_type_id. But BERT does have it for sentences classification, encoder only model.\n",
        "This tell a enconder only model, like the BERT model, which word belog to which sentence.\n",
        "> Example: The dog ate the food. The other dog was sad. I ran away.\n",
        "[0,0,0,0,0,1,1,1,1,1,2,2,2]\n",
        "\n",
        "**chunk lenght** = max 2048 (more than that we need to cut it of)\n",
        "\n",
        "90% of the prompts are gonna fit in 2048 token lenght.\n",
        "The remining 10% might not fit, and might have to cut them off and put the reminders at reminder and it will be process with the next batch.\n",
        "\n",
        "## Example\n",
        "\n",
        "......Machine learning is amazing.\n",
        "\n",
        "\n",
        "remainder = ('input_ids': [1222,3000,2,890],\n",
        "'attention_mask': [1,1,1,1],\n",
        "             'token_type_ids': [] )\n",
        "\n",
        "\n",
        "## The Mistral model\n",
        "\n",
        "We will never going to have an attention mask where we have zeros, because, we are maximizing the traing through flattening them, thats why we have a fix lenght of 2048.\n",
        "inputs_ids = attention_mask"
      ],
      "metadata": {
        "id": "7HJIpjvu0YPd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**El Ejemplo (Chunk de 10)**\n",
        "**Frase Real:** \"Yo salí a jugar\" + `</s>` (EOS)\n",
        "\n",
        "**1. Input IDs (Lo que entra a la GPU)**\n",
        "\n",
        "Aquí ocurre algo curioso. Como configuramos `pad_token = eos_token`, los huecos vacíos se rellenan también con el ID 2.\n",
        "\n",
        "`[101, 234, 33, 222, 2, 2, 2, 2, 2, 2]`\n",
        "\n",
        "* Azul (Datos): `101, 234, 33, 222` (Texto)\n",
        "\n",
        "* Verde (Stop): `2` (El `</s>` que se utilizó para indicar fin)\n",
        "\n",
        "* Gris (Relleno): `2, 2, 2, 2, 2` (El `</s>` que el SISTEMA puso para llenar el hueco)\n",
        "\n",
        "**2. Attention Mask (El Árbitro)**\n",
        "\n",
        "Aquí es donde el modelo distingue cuál \"2\" es importante y cuál es basura.\n",
        "\n",
        "[1, 1, 1, 1, 1, 0, 0, 0, 0, 0]\n",
        "\n",
        "Los primeros cinco `1`: Incluyen el texto Y el primer `</s>`. El modelo DEBE prestar atención a ese primer `2` para aprender cuándo callarse.\n",
        "\n",
        "Los siguientes cinco `0`: Le dicen al modelo: \"Aunque veas un número 2 aquí, ignóralo. No aprendas nada de esto. Es solo soporte estructural\"."
      ],
      "metadata": {
        "id": "HCV5UHtSW2T3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![](https://raw.githubusercontent.com/sebastianperezv/AI_Engineering_Customizing_LLMs_for_Buisness/refs/heads/main/Images/Attention_mask.jpg)"
      ],
      "metadata": {
        "id": "eC-TDekQg4wh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "remainder = {'input_ids': [],\n",
        "             'attention_mask': [],\n",
        "             'token_type_ids': [] } # Empty"
      ],
      "metadata": {
        "id": "F_CEPkwX0YqV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Confiusing code we are going to be encoutering\n",
        "\n",
        "We do not need this on AWS SageMaker jupyterlab"
      ],
      "metadata": {
        "id": "2fRKh48_c__m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Star Unpacking with Python\n",
        "\n",
        "Refresher some of the python sintax.\n",
        "\n",
        "Star unpacking, unpacks the elements of an iterable into individual items."
      ],
      "metadata": {
        "id": "_x2F5MDhVeMZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def introduce(name, age, city):\n",
        "  print(f\"Hello, my name is {name}. I am {age} years old and live in {city}\")"
      ],
      "metadata": {
        "id": "puQQ0CBmVfD1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "person_info = ['Alice', 30, \"New York\"]"
      ],
      "metadata": {
        "id": "CsVEz-A2WGrN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Scenario A: The WRONG way (without the * operator\n",
        "introduce(person_info)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "Ipy4B4LpWNI9",
        "outputId": "b3f2daca-3175-48ee-dcd1-8be0516725e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "introduce() missing 2 required positional arguments: 'age' and 'city'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3363138566.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Scenario A: The WRONG way (without the * operator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mintroduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mperson_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: introduce() missing 2 required positional arguments: 'age' and 'city'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scenario B: The RIGHT way (with the * Operator)\n",
        "# the * is going to unpack the list\n",
        "introduce(*person_info)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iz75LPAZWW_n",
        "outputId": "78527626-1356-485e-fba2-6b9a665f247f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello, my name is Alice. I am 30 years old and live in New York\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## itertools import chain\n",
        "\n",
        "`chain()`: takes multiple list and link them together end to aend in to a single sequence. We need to use `list()` to read in and access the elements"
      ],
      "metadata": {
        "id": "Rw7QQ3WWdFkd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**El Problema**: Los modelos como Mixtral tienen una \"ventana de contexto\" fija (en tu código definida como 2048 tokens).\n",
        "\n",
        "* Si una frase tiene 100 tokens, tendrías que rellenar (padding) con 1948 ceros. Esto es un desperdicio enorme de cómputo y dinero.\n",
        "\n",
        "* Si una frase tiene 3000 tokens, se cortaría y perderías información.\n",
        "\n",
        "**La Solución (la función chunk)**: El código implementa una estrategia de flujo continuo:\n",
        "\n",
        "1. Aplanar (Flatten): Toma todos los ejemplos del dataset y los concatena en una fila india interminable de tokens.\n",
        "\n",
        "2. Trocear (Slice): Corta esa fila exactamente cada 2,048 tokens.\n",
        "\n",
        "3. Gestión de Residuos: Si al final de un lote sobran tokens (el \"remainder\"), no los tira. Los guarda y los pone al principio del siguiente lote.\n",
        "\n",
        "**Beneficio:** El modelo siempre recibe bloques llenos de información (2048 tokens reales) sin desperdiciar ni un solo ciclo de GPU en \"padding\"."
      ],
      "metadata": {
        "id": "Yms-u1OCEjU9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from itertools import chain"
      ],
      "metadata": {
        "id": "G-ftJQH_doXr"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is an example sample where 1 batch has 3 chunks. When we do the map in forwards steps, we will be using 1 batch with 1000 samples. Here the data is already tonekized."
      ],
      "metadata": {
        "id": "RweQ2JOu1fHf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# sample represents a simple batch of data\n",
        "sample = {\n",
        "    # Token IDs\n",
        "    'input_ids': [\n",
        "        # I   Like  Food\n",
        "        [101, 4983, 2], # dataset[0]['text']\n",
        "        [101, 2023, 2003, 2], # dataset[1]['text']\n",
        "        [101, 2759, 2007, 4937, 2] # dataset[2]['text']\n",
        "    ],\n",
        "    'attention_mask': [\n",
        "        # On Mistral model we have fix size chunk lenght of\n",
        "        # 2048\n",
        "        # On each chunk we want 2048 token\n",
        "        [1, 1, 1],\n",
        "        [1, 1, 1, 1],\n",
        "        [1, 1, 1, 1, 1]\n",
        "    ]\n",
        "}"
      ],
      "metadata": {
        "id": "0F8J6KvSdLp2"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The goal is to take all the input_ids and flatt them out in to a single array because we want to chop it up into uniform chunck length each equal to 2048:\n",
        "[101, 4983, 102, 101, 2023, 2003, 102, 101, 2759, 2007, 4937, 102]\n",
        "\n",
        "Once we flatt them out we can cho it up into the chunck sizes that we desire. And when we go back to fine tunning tha chunck size is going to be 2048.\n",
        "[101, 4983, 102, CHOP HERE 101, 2023, 2003, CHOP HERE 102, 101, 2759, CHOP HERE 2007, 4937, 102]"
      ],
      "metadata": {
        "id": "BFrV0sI6jCks"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(sample)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LdwEMA0cmUJz",
        "outputId": "ecc7d652-00a1-4e00-d6f6-66df80b92c16"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': [[101, 4983, 2], [101, 2023, 2003, 2], [101, 2759, 2007, 4937, 2]], 'attention_mask': [[1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1]]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list(chain(*sample['input_ids']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nDZ5ZggWh5j2",
        "outputId": "da07701f-a1c6-478f-8cb5-1b877e15db0e"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[101, 4983, 2, 101, 2023, 2003, 2, 101, 2759, 2007, 4937, 2]"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# flatten the input array\n",
        "# keys: input_ids, attention_mask\n",
        "\n",
        "concatenated_examples = {k: list(chain(*sample[k])) for k in sample.keys()}\n",
        "# list(chain()) make the combination from [101, 4983, 2], [101, 2023, 2003, 2], [101, 2759, 2007, 4937, 2]\n",
        "# to [101, 4983, 2, 101, 2023, 2003, 2, 101, 2759, 2007, 4937, 2]\n",
        "concatenated_examples"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HnahjA-CkNoK",
        "outputId": "5728792c-3fbd-4b1d-a23c-d27ab5244a30"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': [101, 4983, 2, 101, 2023, 2003, 2, 101, 2759, 2007, 4937, 2],\n",
              " 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The concatenated_example is a dictionary hat has to keys: input_ids and attention_mask\n"
      ],
      "metadata": {
        "id": "R5WmdigwmlOF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Understanding Batching\n",
        "\n",
        "We are going to talk about the remainder and how we deal with it.\n",
        "\n",
        "From the batches we are going to create chunks and each chunck soulg have a size of 2048. But this is not a eprfect owrld so we are gonna have remainders and we dont wanna throw out usefull training data so we just wanna put the remainder in the next batch,"
      ],
      "metadata": {
        "id": "y8_u5v4Pofug"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from itertools import chain\n",
        "\n",
        "remainder = {'input_ids': [], 'attention_mask': []}\n",
        "print(\"----Initial State----\")\n",
        "print(f'Initial Remainder: {remainder}\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SZOcoaoCogMK",
        "outputId": "a55eedeb-349a-44cf-89f5-7db9628566a1"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----Initial State----\n",
            "Initial Remainder: {'input_ids': [], 'attention_mask': []}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Round 1"
      ],
      "metadata": {
        "id": "u_xa4xNBrLqV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_1 = {\n",
        "    'input_ids': [\n",
        "        [101, 4983, 2],\n",
        "        [101, 2023, 2003, 2],\n",
        "        [101, 2759, 2007, 4937, 2]\n",
        "    ],\n",
        "    'attention_mask': [\n",
        "        [1, 1, 1],\n",
        "        [1, 1, 1, 1],\n",
        "        [1, 1, 1, 1, 1]\n",
        "    ]\n",
        "}"
      ],
      "metadata": {
        "id": "GCAtMHb_rNeG"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('1. Input for Round 1:', batch_1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8D1AwoqWrqin",
        "outputId": "db163059-1829-4dc4-bfc7-c328376aad30"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. Input for Round 1: {'input_ids': [[101, 4983, 2], [101, 2023, 2003, 2], [101, 2759, 2007, 4937, 2]], 'attention_mask': [[1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1]]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "concatenated_examples = {k: list(chain(*batch_1[k])) for k in batch_1.keys()}\n",
        "print(\"\\n2. After flattening Batch 1:\", concatenated_examples)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tt64VI-_rzCK",
        "outputId": "9c801a02-91a6-466e-e3e1-3a18bf9d4788"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "2. After flattening Batch 1: {'input_ids': [101, 4983, 2, 101, 2023, 2003, 2, 101, 2759, 2007, 4937, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This is the second line: prepending the (currently empty) remainder\n",
        "# we are adding the remainders to the current chunck\n",
        "final_stream = {\n",
        "    k: remainder[k] + concatenated_examples[k] for k in concatenated_examples.keys()\n",
        "}"
      ],
      "metadata": {
        "id": "AUgB6yRPsVGO"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n3. Final stream after adding remainder:\", final_stream)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NTZXRLc5s8JL",
        "outputId": "e030d880-10c2-4a90-b22e-70d45038b977"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "3. Final stream after adding remainder: {'input_ids': [101, 4983, 2, 101, 2023, 2003, 2, 101, 2759, 2007, 4937, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For demostration let's calculate what the reminder Would be"
      ],
      "metadata": {
        "id": "z0yhjHkuu5NK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# For demostration let's calculate what the reminder Would be\n",
        "# we will use a chunk leght of 10. The stream has 12 tokens\n",
        "# So, the remainder will be at last 2 tokens\n",
        "# items() we access the keys and the values\n",
        "remainder = {k: v[10:] for k, v in final_stream.items()}"
      ],
      "metadata": {
        "id": "8udr8VlNvBDk"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n4. New remainder calculated for next round:\", remainder)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qaVwB4SkvYjU",
        "outputId": "7cbe45da-3c52-4f90-cae8-a36fa80bce34"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "4. New remainder calculated for next round: {'input_ids': [4937, 2], 'attention_mask': [1, 1]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Round 2"
      ],
      "metadata": {
        "id": "IkZ2LerOvZMh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_2 = {\n",
        "    \"input_ids\": [\n",
        "        [21, 22, 23, 24, 2],\n",
        "        [26, 27, 28, 29, 2]\n",
        "    ],\n",
        "    \"attention_mask\": [\n",
        "        [1, 1, 1, 1, 1],\n",
        "        [1, 1, 1, 1, 1]\n",
        "    ]\n",
        "}\n",
        "\n",
        "print(\"1. Input for Round 2:\", batch_2)\n",
        "print(f\"(Note: the current remainder from round 1 is: {remainder})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rW3FsG3UwhyU",
        "outputId": "37d685cd-f345-4960-cf37-a534b085a220"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. Input for Round 2: {'input_ids': [[21, 22, 23, 24, 2], [26, 27, 28, 29, 2]], 'attention_mask': [[1, 1, 1, 1, 1], [1, 1, 1, 1, 1]]}\n",
            "(Note: the current remainder from round 1 is: {'input_ids': [4937, 2], 'attention_mask': [1, 1]})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# First line again: flattening Batch 2\n",
        "concatenated_examples = {k: list(chain(*batch_2[k])) for k in batch_2.keys()}\n",
        "print(\"\\n2. After flattening Batch 2:\", concatenated_examples)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RjF88-dXxGbo",
        "outputId": "82f792bd-a1e8-440b-c535-fad187c5064d"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "2. After flattening Batch 2: {'input_ids': [21, 22, 23, 24, 2, 26, 27, 28, 29, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Second line again: prepending the remainder FROM ROUND 1\n",
        "final_stream = {\n",
        "    k: remainder[k] + concatenated_examples[k] for k in concatenated_examples.keys()\n",
        "}"
      ],
      "metadata": {
        "id": "4uhYvq3ryqTH"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n3. Final Stream after adding remainder:\", final_stream)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ZWjFiN_y74N",
        "outputId": "61842185-0bdf-447b-ea3c-110d173c153a"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "3. Final Stream after adding remainder: {'input_ids': [4937, 2, 21, 22, 23, 24, 2, 26, 27, 28, 29, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Slicing and Chunking our Dataset"
      ],
      "metadata": {
        "id": "XAe-HXdyz4gM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# SETUP\n",
        "# we are going to use chunk of 5 tokens\n",
        "# but for the fine tune project we will be using 2048\n",
        "chunk_length = 5 # 2048"
      ],
      "metadata": {
        "id": "YR3oarFAz5Y-"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This is our \"Before\" state. A dictioary where each key holds one long,\n",
        "# continuous list of tokens\n",
        "concatenated_examples = {\n",
        "    'input_ids': [10, 11, 12, 13, 14, 20, 21, 22, 23, 24, 30, 31, 32, 33, 34],\n",
        "    'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
        "}"
      ],
      "metadata": {
        "id": "ciCi9-wu-zgM"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This is the total number of tokens we will slice up #1 5\n",
        "batch_chunk_length = len(concatenated_examples['input_ids'])\n",
        "print(batch_chunk_length)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q_0ohgJE_n0t",
        "outputId": "5e96443e-8a24-44ab-c53e-c699def80838"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Before silicng\n",
        "print(\"This is our long, continuous stream of tokens:\")\n",
        "print(concatenated_examples)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K80TOKjM_zaU",
        "outputId": "66a33db9-0b2a-4d83-dfac-94921e43604d"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is our long, continuous stream of tokens:\n",
            "{'input_ids': [10, 11, 12, 13, 14, 20, 21, 22, 23, 24, 30, 31, 32, 33, 34], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Silicing"
      ],
      "metadata": {
        "id": "lpQWgEaFANea"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The operation\n",
        "# this is the line of code that performs the slicing\n",
        "# range(start, stop, step) -> (0, 15, 5)\n",
        "result = {\n",
        "    k: [t[i : i + chunk_length] for i in range(0, batch_chunk_length, chunk_length)] for k, t in concatenated_examples.items()\n",
        "}"
      ],
      "metadata": {
        "id": "BJUooRz4AVDY"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L9XfOctzBaK6",
        "outputId": "5a165fd8-75c6-4c38-8e83-9681011ad85f"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': [[10, 11, 12, 13, 14],\n",
              "  [20, 21, 22, 23, 24],\n",
              "  [30, 31, 32, 33, 34]],\n",
              " 'attention_mask': [[1, 1, 1, 1, 1], [1, 1, 1, 1, 1], [1, 1, 1, 1, 1]]}"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The result\n",
        "print(\"----After Slicing----\")\n",
        "print(\"The stream has been chopped into a list of smaller lists (chunks):\")\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sw7oo3a2Ba5u",
        "outputId": "82001dcf-f31f-45ed-d876-e9aeb237901b"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----After Slicing----\n",
            "The stream has been chopped into a list of smaller lists (chunks):\n",
            "{'input_ids': [[10, 11, 12, 13, 14], [20, 21, 22, 23, 24], [30, 31, 32, 33, 34]], 'attention_mask': [[1, 1, 1, 1, 1], [1, 1, 1, 1, 1], [1, 1, 1, 1, 1]]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating our Custom Chunking Function\n",
        "\n",
        "We are going to define a function that will do everything for us. It will chunck up all the samples into length of 2048 tokens."
      ],
      "metadata": {
        "id": "QHxdpS26DG12"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def chunk(sample, chunk_length = 2048):\n",
        "\n",
        "  global remainder # we want to be able to access the remainder dictionary to put the remainders in\n",
        "  #print(len(sample['inputs_ids']), 'first') # we have a thousand samples\n",
        "  #print(len(sample['inputs_ids'][999]), 'second') # the 1 thousand sample has this result of tokens\n",
        "\n",
        "  concatenated_examples = {k: list(chain(*sample[k])) for k in sample.keys()}\n",
        "\n",
        "  concatenated_examples = {\n",
        "      k: remainder[k] + concatenated_examples[k] for k in concatenated_examples.keys()\n",
        "  }\n",
        "\n",
        "  batch_total_length = len(concatenated_examples[list(sample.keys())[0]]) # how long is 'input_ids'\n",
        "  # print(batch_total_length, 'third') # total number of tokens in this batch\n",
        "  aux = batch_total_length\n",
        "\n",
        "  if batch_total_length > chunk_length: # 2048\n",
        "    # How many chunks can we fit that perfectly set in 2048?\n",
        "    batch_total_length = (batch_total_length // chunk_length) * chunk_length\n",
        "\n",
        "  #print(batch_total_length,'fourth')\n",
        "  # do the chunking\n",
        "  result = {\n",
        "      k: [t[i : i + chunk_length] for i in range(0, batch_total_length, chunk_length)] for k, t in concatenated_examples.items()\n",
        "  }\n",
        "\n",
        "  # the remainders are goin to be added to the remainder dictionary\n",
        "  remainder = { # what is left\n",
        "      k: concatenated_examples[k][batch_total_length:] for k in concatenated_examples.keys()\n",
        "  }\n",
        "\n",
        "  #print(batch_total_length,'fifth') # Number of chunks with 2048 tokens from the first batch\n",
        "  #print(f'There will be {aux-batch_total_length} tokens from the first batch that will be put into the remainder dictionary, and that will be processed withth next batch')\n",
        "  result['labels'] = result['input_ids'].copy()\n",
        "  return result"
      ],
      "metadata": {
        "id": "C2zVdAUhDxil"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tokenizing our Dataset\n",
        "\n",
        "we just have finished the `chunk()` function which expects a sample.\n",
        "\n",
        "Example of a sample:\n",
        "\n",
        "```python\n",
        "# this batch has 3 sample with their corresponding attention mask\n",
        "sample = {\n",
        "    # Token IDs\n",
        "    'input_ids': [\n",
        "        # I   Like  Food\n",
        "        # Here they are tokenized\n",
        "        [101, 4983, 102], # think like this is the prompt\n",
        "        [101, 2023, 2003, 102],\n",
        "        [101, 2759, 2007, 4937, 102]\n",
        "    ],\n",
        "    'attention_mask': [\n",
        "        # On Mistral model we have fix size chunk lenght of\n",
        "        # 2048\n",
        "        # On each chunk we want 2048 token\n",
        "        [1, 1, 1],\n",
        "        [1, 1, 1, 1],\n",
        "        [1, 1, 1, 1, 1]\n",
        "    ]\n",
        "}\n",
        "```\n",
        "\n",
        "Right now our code is not tokenized thats why we are gonna have to tokenized the whole dataset before we run the `chunk()` function.\n",
        "\n",
        "`batched = True`\n",
        "> by default the value for the batches size is a 1000. That means, when we call the chunk function we are gonna call it with a 1000 samples.\n",
        "chunk() function will reciebe a 1000 tokenized samples and then it creates anew set of samples where eachs sample has a length 2048.\n",
        "\n",
        "`remove_columns = list(dataset.features)`\n",
        "> why are we doing this again?\n",
        "We already have removed instruccion, context, response and category.\n",
        "However, once we tokenize the entire input and we have the `result['labels']` we actually no longer need the `sample['text']` because we already have the input **tokenized**."
      ],
      "metadata": {
        "id": "aQatxqrOR0VA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explaining the next code:\n",
        "```python\n",
        ".map(\n",
        "    partial(chunk, chunk_length),\n",
        "    batched = True\n",
        ")\n",
        "```\n",
        "What the partial does:\n",
        "```python\n",
        "def new_function(sample):\n",
        "  # The chunk_length is already \"frozen\" to 2048\n",
        "  return chunk(sample, chunk_length=2048)\n",
        "```"
      ],
      "metadata": {
        "id": "-GtlyudlCxA1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example\n",
        "sample = tokenizer(dataset[:5]['text'])\n",
        "sample"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "A2e84AZHzQRY",
        "outputId": "18106fe3-2e0f-4c75-a3b9-fc8a3462b5b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': [[1, 774, 3133, 3112, 13, 7477, 863, 8471, 6664, 1149, 10513, 28804, 13, 13, 27332, 14268, 13, 28790, 361, 6207, 6664, 28725, 272, 11674, 1141, 302, 8471, 6664, 28415, 367, 884, 14374, 28725, 349, 396, 9972, 28733, 5527, 2423, 1081, 28723, 661, 349, 272, 7639, 2423, 1081, 486, 17675, 1669, 298, 938, 272, 8471, 5804, 28723, 661, 901, 4697, 3345, 356, 28705, 28770, 28740, 3628, 28705, 28750, 28734, 28734, 28734, 390, 8471, 8836, 28725, 395, 989, 11475, 356, 264, 2692, 7103, 28723, 661, 6914, 1419, 3837, 390, 264, 3014, 2423, 1081, 297, 6664, 28742, 28713, 12866, 2668, 1024, 272, 17347, 302, 1094, 673, 28707, 6664, 297, 4074, 28705, 28750, 28734, 28734, 28740, 28723, 415, 2423, 1081, 659, 1854, 10039, 298, 5090, 7031, 28705, 28770, 28750, 9245, 297, 6664, 28725, 477, 14546, 28713, 297, 1896, 278, 28726, 1564, 28725, 19611, 304, 14469, 28723, 13, 13, 27332, 26307, 13, 28790, 361, 6207, 6664, 901, 4697, 3345, 356, 28705, 28770, 28740, 3628, 28705, 28750, 28734, 28734, 28734, 390, 8471, 8836, 28725, 395, 989, 11475, 356, 264, 2692, 7103, 28723, 2], [1, 774, 3133, 3112, 13, 26703, 349, 264, 7018, 302, 8006, 28804, 1791, 386, 442, 399, 1845, 13, 13, 27332, 26307, 13, 1551, 386, 2], [1, 774, 3133, 3112, 13, 7638, 541, 3730, 1190, 13145, 354, 1043, 1671, 2130, 28804, 13, 13, 27332, 26307, 13, 11658, 1190, 938, 272, 6370, 297, 652, 1997, 782, 298, 1840, 706, 6774, 395, 3408, 304, 6521, 2922, 352, 354, 1043, 15772, 302, 727, 28723, 2], [1, 774, 3133, 3112, 13, 2707, 535, 28742, 28713, 4386, 506, 1712, 19244, 28747, 17723, 28725, 14216, 28724, 28725, 304, 767, 28809, 28713, 272, 1141, 302, 272, 4008, 5690, 28804, 13, 13, 27332, 26307, 13, 1014, 1141, 302, 272, 4008, 5690, 349, 14003, 2], [1, 774, 3133, 3112, 13, 7477, 403, 4660, 28709, 10270, 9227, 271, 2331, 5381, 28804, 13, 13, 27332, 14268, 13, 28796, 300, 271, 2331, 403, 5381, 297, 25694, 314, 2587, 367, 1013, 530, 482, 356, 4398, 28705, 28740, 28734, 28725, 28705, 28740, 28774, 28783, 28740, 28723, 2530, 7461, 1077, 477, 1486, 2052, 28725, 400, 7298, 272, 475, 28740, 6165, 4489, 330, 3225, 4083, 401, 2950, 28718, 18377, 297, 28705, 28750, 28734, 28734, 28734, 28723, 5800, 400, 9928, 286, 390, 264, 4725, 28722, 755, 826, 297, 28705, 28750, 28734, 28734, 28740, 28725, 400, 863, 459, 1156, 1188, 304, 272, 4489, 403, 312, 1946, 601, 298, 272, 475, 28750, 6165, 438, 272, 948, 302, 272, 28705, 28750, 28734, 28734, 28740, 3302, 28723, 560, 28705, 28750, 28734, 28734, 28750, 28725, 400, 4142, 298, 272, 475, 28750, 4489, 451, 3156, 1319, 1783, 28708, 28723, 650, 3246, 264, 4392, 4385, 390, 264, 18306, 4725, 28722, 755, 826, 304, 272, 4489, 1747, 272, 16928, 297, 28705, 28750, 28734, 28734, 28750, 304, 403, 19075, 297, 28705, 28750, 28734, 28734, 28770, 28723, 650, 4226, 1287, 9019, 1996, 28705, 28750, 28734, 28734, 28782, 28723, 560, 4074, 28705, 28750, 28734, 28734, 28782, 28725, 400, 4142, 298, 272, 475, 28750, 4489, 5684, 286, 691, 24510, 357, 563, 28723, 560, 28705, 28750, 28734, 28734, 28784, 28725, 400, 4142, 298, 272, 475, 28750, 4489, 550, 815, 301, 524, 8898, 28723, 5800, 400, 3246, 264, 4392, 4385, 390, 264, 18306, 4725, 28722, 755, 826, 28725, 516, 17885, 403, 4226, 2108, 1938, 272, 5561, 28723, 560, 28705, 28750, 28734, 28734, 28787, 28725, 400, 4142, 298, 272, 4720, 13474, 6165, 4489, 8550, 667, 25694, 314, 2587, 325, 28714, 795, 5243, 23605, 25694, 314, 2587, 28731, 2818, 297, 516, 1862, 4424, 28723, 650, 4226, 390, 264, 4392, 4385, 304, 272, 4489, 403, 19075, 298, 475, 28750, 297, 28705, 28750, 28734, 28734, 28783, 28723, 5800, 400, 863, 459, 1156, 390, 1188, 28725, 400, 1309, 4226, 297, 1287, 9019, 28723, 560, 28705, 28750, 28734, 28740, 28734, 28725, 400, 4142, 298, 24450, 304, 7298, 10407, 4403, 17018, 566, 276, 28723, 560, 4398, 28705, 28750, 28734, 28740, 28734, 28725, 400, 4253, 298, 4720, 304, 7298, 272, 475, 28750, 4489, 25560, 494, 4879, 13402, 20996, 1426, 28718, 28723, 650, 4226, 2608, 390, 264, 18306, 4725, 28722, 755, 826, 304, 4982, 852, 1996, 28705, 28750, 28734, 28740, 28750, 739, 400, 15451, 28723, 13, 13, 27332, 26307, 13, 28738, 14016, 10270, 9227, 271, 2331, 403, 5381, 356, 4398, 28705, 28740, 28734, 28725, 28740, 28774, 28783, 28740, 28723, 2]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = chunk(sample=sample, chunk_length=5)"
      ],
      "metadata": {
        "id": "DeFqpWO70BYy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "GMTYUroz10wd",
        "outputId": "0fc3a6a2-5ade-4ce7-8e36-f42354e535e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': [[11, 12, 1, 774, 3133],\n",
              "  [3112, 13, 7477, 863, 8471],\n",
              "  [6664, 1149, 10513, 28804, 13],\n",
              "  [13, 27332, 14268, 13, 28790],\n",
              "  [361, 6207, 6664, 28725, 272],\n",
              "  [11674, 1141, 302, 8471, 6664],\n",
              "  [28415, 367, 884, 14374, 28725],\n",
              "  [349, 396, 9972, 28733, 5527],\n",
              "  [2423, 1081, 28723, 661, 349],\n",
              "  [272, 7639, 2423, 1081, 486],\n",
              "  [17675, 1669, 298, 938, 272],\n",
              "  [8471, 5804, 28723, 661, 901],\n",
              "  [4697, 3345, 356, 28705, 28770],\n",
              "  [28740, 3628, 28705, 28750, 28734],\n",
              "  [28734, 28734, 390, 8471, 8836],\n",
              "  [28725, 395, 989, 11475, 356],\n",
              "  [264, 2692, 7103, 28723, 661],\n",
              "  [6914, 1419, 3837, 390, 264],\n",
              "  [3014, 2423, 1081, 297, 6664],\n",
              "  [28742, 28713, 12866, 2668, 1024],\n",
              "  [272, 17347, 302, 1094, 673],\n",
              "  [28707, 6664, 297, 4074, 28705],\n",
              "  [28750, 28734, 28734, 28740, 28723],\n",
              "  [415, 2423, 1081, 659, 1854],\n",
              "  [10039, 298, 5090, 7031, 28705],\n",
              "  [28770, 28750, 9245, 297, 6664],\n",
              "  [28725, 477, 14546, 28713, 297],\n",
              "  [1896, 278, 28726, 1564, 28725],\n",
              "  [19611, 304, 14469, 28723, 13],\n",
              "  [13, 27332, 26307, 13, 28790],\n",
              "  [361, 6207, 6664, 901, 4697],\n",
              "  [3345, 356, 28705, 28770, 28740],\n",
              "  [3628, 28705, 28750, 28734, 28734],\n",
              "  [28734, 390, 8471, 8836, 28725],\n",
              "  [395, 989, 11475, 356, 264],\n",
              "  [2692, 7103, 28723, 2, 1],\n",
              "  [774, 3133, 3112, 13, 26703],\n",
              "  [349, 264, 7018, 302, 8006],\n",
              "  [28804, 1791, 386, 442, 399],\n",
              "  [1845, 13, 13, 27332, 26307],\n",
              "  [13, 1551, 386, 2, 1],\n",
              "  [774, 3133, 3112, 13, 7638],\n",
              "  [541, 3730, 1190, 13145, 354],\n",
              "  [1043, 1671, 2130, 28804, 13],\n",
              "  [13, 27332, 26307, 13, 11658],\n",
              "  [1190, 938, 272, 6370, 297],\n",
              "  [652, 1997, 782, 298, 1840],\n",
              "  [706, 6774, 395, 3408, 304],\n",
              "  [6521, 2922, 352, 354, 1043],\n",
              "  [15772, 302, 727, 28723, 2],\n",
              "  [1, 774, 3133, 3112, 13],\n",
              "  [2707, 535, 28742, 28713, 4386],\n",
              "  [506, 1712, 19244, 28747, 17723],\n",
              "  [28725, 14216, 28724, 28725, 304],\n",
              "  [767, 28809, 28713, 272, 1141],\n",
              "  [302, 272, 4008, 5690, 28804],\n",
              "  [13, 13, 27332, 26307, 13],\n",
              "  [1014, 1141, 302, 272, 4008],\n",
              "  [5690, 349, 14003, 2, 1],\n",
              "  [774, 3133, 3112, 13, 7477],\n",
              "  [403, 4660, 28709, 10270, 9227],\n",
              "  [271, 2331, 5381, 28804, 13],\n",
              "  [13, 27332, 14268, 13, 28796],\n",
              "  [300, 271, 2331, 403, 5381],\n",
              "  [297, 25694, 314, 2587, 367],\n",
              "  [1013, 530, 482, 356, 4398],\n",
              "  [28705, 28740, 28734, 28725, 28705],\n",
              "  [28740, 28774, 28783, 28740, 28723],\n",
              "  [2530, 7461, 1077, 477, 1486],\n",
              "  [2052, 28725, 400, 7298, 272],\n",
              "  [475, 28740, 6165, 4489, 330],\n",
              "  [3225, 4083, 401, 2950, 28718],\n",
              "  [18377, 297, 28705, 28750, 28734],\n",
              "  [28734, 28734, 28723, 5800, 400],\n",
              "  [9928, 286, 390, 264, 4725],\n",
              "  [28722, 755, 826, 297, 28705],\n",
              "  [28750, 28734, 28734, 28740, 28725],\n",
              "  [400, 863, 459, 1156, 1188],\n",
              "  [304, 272, 4489, 403, 312],\n",
              "  [1946, 601, 298, 272, 475],\n",
              "  [28750, 6165, 438, 272, 948],\n",
              "  [302, 272, 28705, 28750, 28734],\n",
              "  [28734, 28740, 3302, 28723, 560],\n",
              "  [28705, 28750, 28734, 28734, 28750],\n",
              "  [28725, 400, 4142, 298, 272],\n",
              "  [475, 28750, 4489, 451, 3156],\n",
              "  [1319, 1783, 28708, 28723, 650],\n",
              "  [3246, 264, 4392, 4385, 390],\n",
              "  [264, 18306, 4725, 28722, 755],\n",
              "  [826, 304, 272, 4489, 1747],\n",
              "  [272, 16928, 297, 28705, 28750],\n",
              "  [28734, 28734, 28750, 304, 403],\n",
              "  [19075, 297, 28705, 28750, 28734],\n",
              "  [28734, 28770, 28723, 650, 4226],\n",
              "  [1287, 9019, 1996, 28705, 28750],\n",
              "  [28734, 28734, 28782, 28723, 560],\n",
              "  [4074, 28705, 28750, 28734, 28734],\n",
              "  [28782, 28725, 400, 4142, 298],\n",
              "  [272, 475, 28750, 4489, 5684],\n",
              "  [286, 691, 24510, 357, 563],\n",
              "  [28723, 560, 28705, 28750, 28734],\n",
              "  [28734, 28784, 28725, 400, 4142],\n",
              "  [298, 272, 475, 28750, 4489],\n",
              "  [550, 815, 301, 524, 8898],\n",
              "  [28723, 5800, 400, 3246, 264],\n",
              "  [4392, 4385, 390, 264, 18306],\n",
              "  [4725, 28722, 755, 826, 28725],\n",
              "  [516, 17885, 403, 4226, 2108],\n",
              "  [1938, 272, 5561, 28723, 560],\n",
              "  [28705, 28750, 28734, 28734, 28787],\n",
              "  [28725, 400, 4142, 298, 272],\n",
              "  [4720, 13474, 6165, 4489, 8550],\n",
              "  [667, 25694, 314, 2587, 325],\n",
              "  [28714, 795, 5243, 23605, 25694],\n",
              "  [314, 2587, 28731, 2818, 297],\n",
              "  [516, 1862, 4424, 28723, 650],\n",
              "  [4226, 390, 264, 4392, 4385],\n",
              "  [304, 272, 4489, 403, 19075],\n",
              "  [298, 475, 28750, 297, 28705],\n",
              "  [28750, 28734, 28734, 28783, 28723],\n",
              "  [5800, 400, 863, 459, 1156],\n",
              "  [390, 1188, 28725, 400, 1309],\n",
              "  [4226, 297, 1287, 9019, 28723],\n",
              "  [560, 28705, 28750, 28734, 28740],\n",
              "  [28734, 28725, 400, 4142, 298],\n",
              "  [24450, 304, 7298, 10407, 4403],\n",
              "  [17018, 566, 276, 28723, 560],\n",
              "  [4398, 28705, 28750, 28734, 28740],\n",
              "  [28734, 28725, 400, 4253, 298],\n",
              "  [4720, 304, 7298, 272, 475],\n",
              "  [28750, 4489, 25560, 494, 4879],\n",
              "  [13402, 20996, 1426, 28718, 28723],\n",
              "  [650, 4226, 2608, 390, 264],\n",
              "  [18306, 4725, 28722, 755, 826],\n",
              "  [304, 4982, 852, 1996, 28705],\n",
              "  [28750, 28734, 28740, 28750, 739],\n",
              "  [400, 15451, 28723, 13, 13],\n",
              "  [27332, 26307, 13, 28738, 14016],\n",
              "  [10270, 9227, 271, 2331, 403],\n",
              "  [5381, 356, 4398, 28705, 28740],\n",
              "  [28734, 28725, 28740, 28774, 28783]],\n",
              " 'attention_mask': [[1, 1, 1, 1, 1],\n",
              "  [1, 1, 1, 1, 1],\n",
              "  [1, 1, 1, 1, 1],\n",
              "  [1, 1, 1, 1, 1],\n",
              "  [1, 1, 1, 1, 1],\n",
              "  [1, 1, 1, 1, 1],\n",
              "  [1, 1, 1, 1, 1],\n",
              "  [1, 1, 1, 1, 1],\n",
              "  [1, 1, 1, 1, 1],\n",
              "  [1, 1, 1, 1, 1],\n",
              "  [1, 1, 1, 1, 1],\n",
              "  [1, 1, 1, 1, 1],\n",
              "  [1, 1, 1, 1, 1],\n",
              "  [1, 1, 1, 1, 1],\n",
              "  [1, 1, 1, 1, 1],\n",
              "  [1, 1, 1, 1, 1],\n",
              "  [1, 1, 1, 1, 1],\n",
              "  [1, 1, 1, 1, 1],\n",
              "  [1, 1, 1, 1, 1],\n",
              "  [1, 1, 1, 1, 1],\n",
              "  [1, 1, 1, 1, 1],\n",
              "  [1, 1, 1, 1, 1],\n",
              "  [1, 1, 1, 1, 1],\n",
              "  [1, 1, 1, 1, 1],\n",
              "  [1, 1, 1, 1, 1],\n",
              "  [1, 1, 1, 1, 1],\n",
              "  [1, 1, 1, 1, 1],\n",
              "  [1, 1, 1, 1, 1],\n",
              "  [1, 1, 1, 1, 1],\n",
              "  [1, 1, 1, 1, 1],\n",
              "  [1, 1, 1, 1, 1],\n",
              "  [1, 1, 1, 1, 1],\n",
              "  [1, 1, 1, 1, 1],\n",
              "  [1, 1, 1, 1, 1],\n",
              "  [1, 1, 1, 1, 1],\n",
              "  [1, 1, 1, 1, 1],\n",
              "  [1, 1, 1, 1, 1],\n",
              "  [1, 1, 1, 1, 1],\n",
              "  [1, 1, 1, 1, 1],\n",
              "  [1, 1, 1, 1, 1],\n",
              "  [1, 1, 1, 1, 1],\n",
              "  [1, 1, 1, 1, 1],\n",
              "  [1, 1, 1, 1, 1],\n",
              "  [1, 1, 1, 1, 1],\n",
              "  [1, 1, 1, 1, 1],\n",
              "  [1, 1, 1, 1, 1],\n",
              "  [1, 1, 1, 1, 1],\n",
              "  [1, 1, 1, 1, 1],\n",
              "  [1, 1, 1, 1, 1],\n",
              "  [1, 1, 1, 1, 1],\n",
              "  [1, 1, 1, 1, 1],\n",
              "  [1, 1, 1, 1, 1],\n",
              "  [1, 1, 1, 1, 1],\n",
              "  [1, 1, 1, 1, 1],\n",
              "  [1, 1, 1, 1, 1],\n",
              "  [1, 1, 1, 1, 1],\n",
              "  [1, 1, 1, 1, 1],\n",
              "  [1, 1, 1, 1, 1],\n",
              "  [1, 1, 1, 1, 1],\n",
              "  [1, 1, 1, 1, 1],\n",
              "  [1, 1, 1, 1, 1],\n",
              "  [1, 1, 1, 1, 1],\n",
              "  [1, 1, 1, 1, 1],\n",
              "  [1, 1, 1, 1, 1],\n",
              "  [1, 1, 1, 1, 1],\n",
              "  [1, 1, 1, 1, 1],\n",
              "  [1, 1, 1, 1, 1],\n",
              "  [1, 1, 1, 1, 1],\n",
              "  [1, 1, 1, 1, 1],\n",
              "  [1, 1, 1, 1, 1],\n",
              "  [1, 1, 1, 1, 1],\n",
              "  [1, 1, 1, 1, 1],\n",
              "  [1, 1, 1, 1, 1],\n",
              "  [1, 1, 1, 1, 1],\n",
              "  [1, 1, 1, 1, 1],\n",
              "  [1, 1, 1, 1, 1],\n",
              "  [1, 1, 1, 1, 1],\n",
              "  [1, 1, 1, 1, 1],\n",
              "  [1, 1, 1, 1, 1],\n",
              "  [1, 1, 1, 1, 1],\n",
              "  [1, 1, 1, 1, 1],\n",
              "  [1, 1, 1, 1, 1],\n",
              "  [1, 1, 1, 1, 1],\n",
              "  [1, 1, 1, 1, 1],\n",
              "  [1, 1, 1, 1, 1],\n",
              "  [1, 1, 1, 1, 1],\n",
              "  [1, 1, 1, 1, 1],\n",
              "  [1, 1, 1, 1, 1],\n",
              "  [1, 1, 1, 1, 1],\n",
              "  [1, 1, 1, 1, 1],\n",
              "  [1, 1, 1, 1, 1],\n",
              "  [1, 1, 1, 1, 1],\n",
              "  [1, 1, 1, 1, 1],\n",
              "  [1, 1, 1, 1, 1],\n",
              "  [1, 1, 1, 1, 1],\n",
              "  [1, 1, 1, 1, 1],\n",
              "  [1, 1, 1, 1, 1],\n",
              "  [1, 1, 1, 1, 1],\n",
              "  [1, 1, 1, 1, 1],\n",
              "  [1, 1, 1, 1, 1],\n",
              "  [1, 1, 1, 1, 1],\n",
              "  [1, 1, 1, 1, 1],\n",
              "  [1, 1, 1, 1, 1],\n",
              "  [1, 1, 1, 1, 1],\n",
              "  [1, 1, 1, 1, 1],\n",
              "  [1, 1, 1, 1, 1],\n",
              "  [1, 1, 1, 1, 1],\n",
              "  [1, 1, 1, 1, 1],\n",
              "  [1, 1, 1, 1, 1],\n",
              "  [1, 1, 1, 1, 1],\n",
              "  [1, 1, 1, 1, 1],\n",
              "  [1, 1, 1, 1, 1],\n",
              "  [1, 1, 1, 1, 1],\n",
              "  [1, 1, 1, 1, 1],\n",
              "  [1, 1, 1, 1, 1],\n",
              "  [1, 1, 1, 1, 1],\n",
              "  [1, 1, 1, 1, 1],\n",
              "  [1, 1, 1, 1, 1],\n",
              "  [1, 1, 1, 1, 1],\n",
              "  [1, 1, 1, 1, 1],\n",
              "  [1, 1, 1, 1, 1],\n",
              "  [1, 1, 1, 1, 1],\n",
              "  [1, 1, 1, 1, 1],\n",
              "  [1, 1, 1, 1, 1],\n",
              "  [1, 1, 1, 1, 1],\n",
              "  [1, 1, 1, 1, 1],\n",
              "  [1, 1, 1, 1, 1],\n",
              "  [1, 1, 1, 1, 1],\n",
              "  [1, 1, 1, 1, 1],\n",
              "  [1, 1, 1, 1, 1],\n",
              "  [1, 1, 1, 1, 1],\n",
              "  [1, 1, 1, 1, 1],\n",
              "  [1, 1, 1, 1, 1],\n",
              "  [1, 1, 1, 1, 1],\n",
              "  [1, 1, 1, 1, 1],\n",
              "  [1, 1, 1, 1, 1],\n",
              "  [1, 1, 1, 1, 1],\n",
              "  [1, 1, 1, 1, 1],\n",
              "  [1, 1, 1, 1, 1],\n",
              "  [1, 1, 1, 1, 1],\n",
              "  [1, 1, 1, 1, 1]],\n",
              " 'labels': [[11, 12, 1, 774, 3133],\n",
              "  [3112, 13, 7477, 863, 8471],\n",
              "  [6664, 1149, 10513, 28804, 13],\n",
              "  [13, 27332, 14268, 13, 28790],\n",
              "  [361, 6207, 6664, 28725, 272],\n",
              "  [11674, 1141, 302, 8471, 6664],\n",
              "  [28415, 367, 884, 14374, 28725],\n",
              "  [349, 396, 9972, 28733, 5527],\n",
              "  [2423, 1081, 28723, 661, 349],\n",
              "  [272, 7639, 2423, 1081, 486],\n",
              "  [17675, 1669, 298, 938, 272],\n",
              "  [8471, 5804, 28723, 661, 901],\n",
              "  [4697, 3345, 356, 28705, 28770],\n",
              "  [28740, 3628, 28705, 28750, 28734],\n",
              "  [28734, 28734, 390, 8471, 8836],\n",
              "  [28725, 395, 989, 11475, 356],\n",
              "  [264, 2692, 7103, 28723, 661],\n",
              "  [6914, 1419, 3837, 390, 264],\n",
              "  [3014, 2423, 1081, 297, 6664],\n",
              "  [28742, 28713, 12866, 2668, 1024],\n",
              "  [272, 17347, 302, 1094, 673],\n",
              "  [28707, 6664, 297, 4074, 28705],\n",
              "  [28750, 28734, 28734, 28740, 28723],\n",
              "  [415, 2423, 1081, 659, 1854],\n",
              "  [10039, 298, 5090, 7031, 28705],\n",
              "  [28770, 28750, 9245, 297, 6664],\n",
              "  [28725, 477, 14546, 28713, 297],\n",
              "  [1896, 278, 28726, 1564, 28725],\n",
              "  [19611, 304, 14469, 28723, 13],\n",
              "  [13, 27332, 26307, 13, 28790],\n",
              "  [361, 6207, 6664, 901, 4697],\n",
              "  [3345, 356, 28705, 28770, 28740],\n",
              "  [3628, 28705, 28750, 28734, 28734],\n",
              "  [28734, 390, 8471, 8836, 28725],\n",
              "  [395, 989, 11475, 356, 264],\n",
              "  [2692, 7103, 28723, 2, 1],\n",
              "  [774, 3133, 3112, 13, 26703],\n",
              "  [349, 264, 7018, 302, 8006],\n",
              "  [28804, 1791, 386, 442, 399],\n",
              "  [1845, 13, 13, 27332, 26307],\n",
              "  [13, 1551, 386, 2, 1],\n",
              "  [774, 3133, 3112, 13, 7638],\n",
              "  [541, 3730, 1190, 13145, 354],\n",
              "  [1043, 1671, 2130, 28804, 13],\n",
              "  [13, 27332, 26307, 13, 11658],\n",
              "  [1190, 938, 272, 6370, 297],\n",
              "  [652, 1997, 782, 298, 1840],\n",
              "  [706, 6774, 395, 3408, 304],\n",
              "  [6521, 2922, 352, 354, 1043],\n",
              "  [15772, 302, 727, 28723, 2],\n",
              "  [1, 774, 3133, 3112, 13],\n",
              "  [2707, 535, 28742, 28713, 4386],\n",
              "  [506, 1712, 19244, 28747, 17723],\n",
              "  [28725, 14216, 28724, 28725, 304],\n",
              "  [767, 28809, 28713, 272, 1141],\n",
              "  [302, 272, 4008, 5690, 28804],\n",
              "  [13, 13, 27332, 26307, 13],\n",
              "  [1014, 1141, 302, 272, 4008],\n",
              "  [5690, 349, 14003, 2, 1],\n",
              "  [774, 3133, 3112, 13, 7477],\n",
              "  [403, 4660, 28709, 10270, 9227],\n",
              "  [271, 2331, 5381, 28804, 13],\n",
              "  [13, 27332, 14268, 13, 28796],\n",
              "  [300, 271, 2331, 403, 5381],\n",
              "  [297, 25694, 314, 2587, 367],\n",
              "  [1013, 530, 482, 356, 4398],\n",
              "  [28705, 28740, 28734, 28725, 28705],\n",
              "  [28740, 28774, 28783, 28740, 28723],\n",
              "  [2530, 7461, 1077, 477, 1486],\n",
              "  [2052, 28725, 400, 7298, 272],\n",
              "  [475, 28740, 6165, 4489, 330],\n",
              "  [3225, 4083, 401, 2950, 28718],\n",
              "  [18377, 297, 28705, 28750, 28734],\n",
              "  [28734, 28734, 28723, 5800, 400],\n",
              "  [9928, 286, 390, 264, 4725],\n",
              "  [28722, 755, 826, 297, 28705],\n",
              "  [28750, 28734, 28734, 28740, 28725],\n",
              "  [400, 863, 459, 1156, 1188],\n",
              "  [304, 272, 4489, 403, 312],\n",
              "  [1946, 601, 298, 272, 475],\n",
              "  [28750, 6165, 438, 272, 948],\n",
              "  [302, 272, 28705, 28750, 28734],\n",
              "  [28734, 28740, 3302, 28723, 560],\n",
              "  [28705, 28750, 28734, 28734, 28750],\n",
              "  [28725, 400, 4142, 298, 272],\n",
              "  [475, 28750, 4489, 451, 3156],\n",
              "  [1319, 1783, 28708, 28723, 650],\n",
              "  [3246, 264, 4392, 4385, 390],\n",
              "  [264, 18306, 4725, 28722, 755],\n",
              "  [826, 304, 272, 4489, 1747],\n",
              "  [272, 16928, 297, 28705, 28750],\n",
              "  [28734, 28734, 28750, 304, 403],\n",
              "  [19075, 297, 28705, 28750, 28734],\n",
              "  [28734, 28770, 28723, 650, 4226],\n",
              "  [1287, 9019, 1996, 28705, 28750],\n",
              "  [28734, 28734, 28782, 28723, 560],\n",
              "  [4074, 28705, 28750, 28734, 28734],\n",
              "  [28782, 28725, 400, 4142, 298],\n",
              "  [272, 475, 28750, 4489, 5684],\n",
              "  [286, 691, 24510, 357, 563],\n",
              "  [28723, 560, 28705, 28750, 28734],\n",
              "  [28734, 28784, 28725, 400, 4142],\n",
              "  [298, 272, 475, 28750, 4489],\n",
              "  [550, 815, 301, 524, 8898],\n",
              "  [28723, 5800, 400, 3246, 264],\n",
              "  [4392, 4385, 390, 264, 18306],\n",
              "  [4725, 28722, 755, 826, 28725],\n",
              "  [516, 17885, 403, 4226, 2108],\n",
              "  [1938, 272, 5561, 28723, 560],\n",
              "  [28705, 28750, 28734, 28734, 28787],\n",
              "  [28725, 400, 4142, 298, 272],\n",
              "  [4720, 13474, 6165, 4489, 8550],\n",
              "  [667, 25694, 314, 2587, 325],\n",
              "  [28714, 795, 5243, 23605, 25694],\n",
              "  [314, 2587, 28731, 2818, 297],\n",
              "  [516, 1862, 4424, 28723, 650],\n",
              "  [4226, 390, 264, 4392, 4385],\n",
              "  [304, 272, 4489, 403, 19075],\n",
              "  [298, 475, 28750, 297, 28705],\n",
              "  [28750, 28734, 28734, 28783, 28723],\n",
              "  [5800, 400, 863, 459, 1156],\n",
              "  [390, 1188, 28725, 400, 1309],\n",
              "  [4226, 297, 1287, 9019, 28723],\n",
              "  [560, 28705, 28750, 28734, 28740],\n",
              "  [28734, 28725, 400, 4142, 298],\n",
              "  [24450, 304, 7298, 10407, 4403],\n",
              "  [17018, 566, 276, 28723, 560],\n",
              "  [4398, 28705, 28750, 28734, 28740],\n",
              "  [28734, 28725, 400, 4253, 298],\n",
              "  [4720, 304, 7298, 272, 475],\n",
              "  [28750, 4489, 25560, 494, 4879],\n",
              "  [13402, 20996, 1426, 28718, 28723],\n",
              "  [650, 4226, 2608, 390, 264],\n",
              "  [18306, 4725, 28722, 755, 826],\n",
              "  [304, 4982, 852, 1996, 28705],\n",
              "  [28750, 28734, 28740, 28750, 739],\n",
              "  [400, 15451, 28723, 13, 13],\n",
              "  [27332, 26307, 13, 28738, 14016],\n",
              "  [10270, 9227, 271, 2331, 403],\n",
              "  [5381, 356, 4398, 28705, 28740],\n",
              "  [28734, 28725, 28740, 28774, 28783]]}"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "zNMjT2Uy2Yk3",
        "outputId": "a85f8fe6-3333-4314-b709-93f539c3f9c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Con `batched=True` (código actual): `sample['text']` se convierte en una Lista de Strings (de tamaño 1000). `[\"Hola mundo\", \"Instrucción 2\", \"Instrucción 3\", ... hasta 1000]` (La función se ejecuta solo 15 veces para un dataset de 15k)"
      ],
      "metadata": {
        "id": "2Xgelhp65CmS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lm_dataset = dataset.map(\n",
        "    lambda sample: tokenizer(sample['text']), # your input is sample -> do tokenizer(sample['text'])\n",
        "    batched = True, # sends 1000 of samples to the batch\n",
        "    remove_columns = list(dataset.features) # why are we doing this again?\n",
        ").map(\n",
        "    partial(chunk, chunk_length=2048),\n",
        "    batched = True\n",
        ")"
      ],
      "metadata": {
        "id": "tGcGDpVKR1MV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "d78fd1b52ad941d09393613dd4983b22",
            "7096cff3dde24dc5825afc0b1913cc4d",
            "64ef1a5a0f834dc48d35d8cf6f59305e",
            "37d0f903120a41c39da61d407ea108e2",
            "b7e3917cba2a44b2b4f892d20da8b816",
            "9c450a1cbc324473beeaeb764096f01d",
            "8b531ab9374c4917a6362e55c6eb1364",
            "f0e90aaab0bd46f3aa2ddeae19262cdc",
            "24e1a1bb87c04aa694adc5c6a3f08c24",
            "b47f6362da744a08831433a42bdf4a25",
            "c4f4fbd10c484e7b8cdfe2e59564ae5c",
            "4cba8e57c195436084fce969c4e64d76",
            "9845c6f6317242ab92dc9f2186afb05b",
            "1dbfa08cc6ca461e9eb6a043dafaa6ba",
            "c0b27cf67e7d47059514dd02ea98b9c4",
            "3a633e7619af4e8f9004b3a0952f1341",
            "9ba0abe8f55947718f312a6921d93bbc",
            "6e02e28a1e46454facae48935f745ba3",
            "7d09f09bef414e82970ab9a49fe1ee6c",
            "9ae51712ec1a4bf7ab7678f61c719b7d",
            "f0fcea8460db47c1bfc4da4d4bd8dd3a",
            "9813e8d377a54fb590af6ce92585bec0"
          ]
        },
        "outputId": "732055f5-3b36-4d2a-ce6a-f966de591165"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/15011 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d78fd1b52ad941d09393613dd4983b22"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/15011 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4cba8e57c195436084fce969c4e64d76"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Total number of samples: {len(lm_dataset)}\") # you have this many chunks, and each is 2048 tokens long\n",
        "# the number means you have for example 1528 chunks and each chunk has 2048 tokens long"
      ],
      "metadata": {
        "id": "iP-p4ecWEVGS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49686148-279b-4c7e-920e-a7e31fbf82f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of samples: 1528\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Guardar en formato binario\n",
        "lm_dataset.save_to_disk(\"data/dataset_procesado\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "0ae7696ec7fd485d9526de8fbff14415",
            "a9eeb83248d246e187fa7276d6531b42",
            "e93347b3c0be4b2ea4df998c735b6068",
            "fddcc20dc3a74922be243246852b1e8d",
            "14d918da1020481e8a69883f51b0535f",
            "b5dd30ae56f4486788ad8493f23db20b",
            "237e3faf93c14f2884ae06ff70c486db",
            "46955ff233484a8db9d3de8641b93fc5",
            "83f220cffb9f40d2b88222d0c9086028",
            "298503123eb74e2dacc22269103299b2",
            "0c192f7e784f4b63b56484c1d9033028"
          ]
        },
        "id": "8kWShhcIdX6k",
        "outputId": "463f5287-6d7f-427e-fa58-0296da8766e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Saving the dataset (0/1 shards):   0%|          | 0/1528 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0ae7696ec7fd485d9526de8fbff14415"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(lm_dataset[0]['input_ids']),\n",
        "len(lm_dataset[0]['attention_mask'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wBGcXWzMemur",
        "outputId": "b4d1615d-a77b-4f39-89fe-e063288f99b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2048"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Uploading the Training Data to AWS S3\n",
        "\n",
        "Now we are going to upload our data and the tokenized data, our LLM dataset into S3. When we do the training process we are gonna be loading in the traning data from `S3`\n",
        "\n",
        "`ideas-llm-dataset-2025`\n"
      ],
      "metadata": {
        "id": "gNgzYizqcnCn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import s3fs\n",
        "\n",
        "training_input_path = f's3://ideas-llm-dataset-2025/processed/mixtral/dolly/train'\n",
        "\n",
        "lm_dataset.save_to_disk(training_input_path)\n",
        "print(\"Uploading the data set to s3\")"
      ],
      "metadata": {
        "id": "7957l5--coGc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Understanding LoRA and Setting up HuggingFace Estimator\n",
        "\n",
        "Setting Up Hyperparameters for the Training Job\n",
        "\n",
        "We just have finished uploading our dataset to S3. Now we are gonna start setting up the boilerplate code that we need in order to start off a SageMaker training job which in this case is going to be a fine-tuning job."
      ],
      "metadata": {
        "id": "prTtV4g7qUR9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* merge_weights: True:\n",
        "Este es un parámetro personalizado que lee el script run_clm.py. Le dice: \"Al terminar, no me des solo los adaptadores sueltos. Fusiona $W + (B \\times A)$ y guárdame un modelo final listo para usar\"."
      ],
      "metadata": {
        "id": "JYbM4XrltUKy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from sagemaker.huggingface import HuggingFace\n",
        "\n",
        "job_name = f\"mixtral-8x7b-qlora-{time.strftime('%Y-%m-%d-%H-%M-%S', time.localtime())}\"\n",
        "\n",
        "hyperparameters = {\n",
        "    'model_id': model_id,\n",
        "    'dataset_path': '/opt/ml/input/data/training', # this is a specific path\n",
        "    'epochs': 2, # At least 5 if the company is providing enough money\n",
        "    'per_device_train_batch_size': 2, # this is the batch size for training. In every single step our system will process 8 exmples in paralel. (2 per device, 4 gpu)\n",
        "    'lr': 2e-4,\n",
        "    'merge_weights': True, # Indica que al finalizar, queremos fusionar los adaptadores LoRA con el modelo base para tener un solo modelo listo para usar, o mantenerlos separados.\n",
        "}"
      ],
      "metadata": {
        "id": "9GtTs5qRq9uf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating our HuggingFace Estimator in Sagemaker\n",
        "\n",
        "This is an object that we can then call the dot fit method on it, wich starts the training, or in our case, the fine-tuning."
      ],
      "metadata": {
        "id": "IU9PdKYxudRv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "huggingface_estimator = HuggingFace(\n",
        "    entry_point = 'run_clm.py', # havent create this py file yet\n",
        "    source_dir = 'scripts', # this is the directory which includes the entry point scripts and the requierements txt for pur training enviroment\n",
        "    instance_type = 'ml.g5.24xlarge', # the instance that we are going to use to train our model. It has 4 GPUs.\n",
        "    instance_count = 1, # Number of instances user for training\n",
        "    base_job_name = job_name,\n",
        "    role = role, # IAM role used in training to access AWS resources\n",
        "    volume_size = 300, # size EBS volume in gigabytes\n",
        "    transformers_version = '4.28', # Software versions\n",
        "    pytorch_version = '2.0',\n",
        "    py_version = 'py310',\n",
        "    hyperparameters = hyperparameters,\n",
        "    enviroment = {\n",
        "        'HUGGINGFACE_HUB_CACHE': '/tmp/.cache'\n",
        "    }\n",
        ")"
      ],
      "metadata": {
        "id": "hc-N-8oELZbl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* data: Le dices dónde en S3 dejaste los datos procesados.\n",
        "\n",
        "* .fit(): Aquí AWS hace lo siguiente:\n",
        "\n",
        "1. Provisiona la instancia ml.g5.24xlarge (tarda unos 5 min).\n",
        "\n",
        "2. Descarga la imagen de Docker de Hugging Face.\n",
        "\n",
        "3. Descarga el código (run_clm.py) y tus datos desde S3.\n",
        "\n",
        "4. Ejecuta python run_clm.py --epochs 2 ....\n",
        "\n",
        "5. Cuando termina, guarda el modelo en S3 y apaga la máquina para que no sigas pagando."
      ],
      "metadata": {
        "id": "RbbgEd8IvWa3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# last setup\n",
        "data = {'training': training_input_path}\n",
        "huggingface_estimator.fit(data, wait = True)"
      ],
      "metadata": {
        "id": "M5pq2jHwO-r1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# What is LoRA?\n",
        "\n",
        "When training LLM in each layer they have billions of weights, and updating all of them with backpropagation is very time consuming because that means we have to calculate all the gradients for those billions of parameters. Thats where LoRA comes in, and instead of calculating the gradients for all of the values in the weight matrix, we instead we break up W into to smaller matrices BA.\n",
        "\n",
        "Weight matrix (*W* is a matrix in a space of real values with `k:rows` and `d:columns`):\n",
        "\n",
        "$W \\in \\mathbb{R}^{k \\times d}$\n",
        "\n",
        "Break up *W*:\n",
        "\n",
        "$\\Delta W = BA$\n",
        "\n",
        "So whenever there is gradients that we need to calculate we only calculate the Weight update for B and A, which are small matrices. That way we can essentially update the entire frozen W, which is a massive matrix with million of weights, we can updated but we dont updated by calculating the gradients for all the values inside of it, we just simple add or substract to it the chain in W which is the product of two smaller matrices B times A.\n",
        "\n",
        "What we need to understand is that we are not calculating gradients for a large weight matrix, we are calculating gradients for smaller weight matrix BA, and then, once we multiply BA together, they are much smaller so they are more efficient, we add or substract the values to the original big *W* which was frozen.\n",
        "\n",
        "The *r* or *rank* parameter is the most important hyperparameters that controlls the size and expressive power of the fine tunning update.\n",
        "\n",
        "So instead re-training all the billion parameters in a LLM, `LoRA` freezes the original weights and inject a pair of samll trainable matrices B and A into that specific traget layer and r defines the inner dimensions of that matrices, meaning, if the original weights are a 1000 by 1000 matrix, the new matrices will be 1000 by r and r times 1000.\n",
        "\n",
        "where:\n",
        "\n",
        "* $A \\in \\mathbb{R}^{r \\times d}$ is a small trainable matrix\n",
        "* $B \\in \\mathbb{R}^{k \\times r}$ is a small trainable matrix\n",
        "* $r << \\min(k, d)$ *r* is much smaller than *k* or *d*, where *k* is the input dimension of the layer and *d* is the output dimension\n",
        "\n",
        "The effective weight becomes:\n",
        "\n",
        "$W_{\\text{eff}} = W + \\Delta W = W + BA$\n",
        "\n",
        "So only A and B receive gradient updates.\n",
        "\n",
        "## Why use LoRA\n",
        "\n",
        "* Full fine-tuning updates every weight tensor - expensive in memory and compute.\n",
        "* LoRA reduces the number of trainable parameters by two or more orders of magnitude.\n",
        "* In practice it achieves competitive downstream accuracy at a fraction of the cost.\n",
        "\n",
        "When we fine tune a model, *W* is gonna have all the learn weights, so the mistral model that we are gonna fine tune has so much information and knows about the world war, mathematics, religion, etc. But does not know about our specific stuff that we want to fine tune on. That why we need to fit to our fit, we are not going to modify its weight, intead we add to it some of the weight training to *W*."
      ],
      "metadata": {
        "id": "M2Ei0kXgUKLh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LoRA Numerical Example\n",
        "\n",
        "Keep in mind that $A$ and $B$ are smaller, they have far fewer total parameters to train. When youu multiply $B$ times $A$, the resulting matrix will have the same dimensions as the original matrix $W$ which is why the addition is mathematicaly valid.\n",
        "\n",
        "Let\n",
        "\n",
        "* input dim $d = 4$, output dim $k = 4$, rank $r = 2$\n",
        "\n",
        "The initial matrices are:\n",
        "$W = \\begin{bmatrix}\n",
        "1 & 0 & -1 & 2 \\\\\n",
        "0 & 1 & 1 & -1 \\\\\n",
        "2 & -2 & 0 & 0 \\\\\n",
        "1 & 1 & 1 & 1\n",
        "\\end{bmatrix}$,\n",
        "$A =\n",
        "\\begin{bmatrix}\n",
        "0.1 & 0.2 & 0.3 & 0.4 \\\\\n",
        "-0.1 & -0.2 & 0.0 & 0.1\n",
        "\\end{bmatrix}$,\n",
        "$B\\begin{bmatrix}\n",
        "1 & 0 \\\\\n",
        "0 & 1 \\\\\n",
        "0.5 & -0.5 \\\\\n",
        "-1 & 1\n",
        "\\end{bmatrix}$\n",
        "\n",
        "The initial *$\\Delta W$* and the efective weight matrix *$W_{\\text{eff}}$* are caluclated as:\n",
        "\n",
        "$\\Delta W = BA = \\Delta W = \\begin{bmatrix}\n",
        "0.1 & 0.2 & 0.3 & 0.4 \\\\\n",
        "-0.1 & -0.2 & 0.0 & 0.1 \\\\\n",
        "0.1 & 0.2 & 0.15 & 0.15 \\\\\n",
        "-0.2 & -0.4 & -0.3 & -0.3\n",
        "\\end{bmatrix}$,\n",
        "$\n",
        "W_{\\text{eff}} = W + \\Delta W\n",
        "\\begin{bmatrix}\n",
        "1.1 & 0.2 & -0.7 & 2.4 \\\\\n",
        "-0.1 & 0.8 & 1.0 & -0.9 \\\\\n",
        "2.1 & -1.8 & 0.15 & 0.15 \\\\\n",
        "0.8 & 0.6 & 0.7 & 0.7\n",
        "\\end{bmatrix}$\n",
        "\n",
        "## A single Gradient Update Step\n",
        "\n",
        "Now, let's simulate one step pf training. We need an input vector $x$, a target output $y_{\\text{true}}$, a $loss$ function *L*, and a learning rate $alpha$\n",
        "* input: $x = [1,0,0,0$\n",
        "* Target: $y_{\\text{true}} = [1,1,1,1$\n",
        "* Loss Function: L (Sum of Squared errors)\n",
        "* Learning rate: $alpha = 0.1$\n",
        "\n",
        "1. Forward pass: First, we compute the predicted output y = xWeff. With x = [1,0,0,0, this simply selects the first row of Weff cause the pther columns from x are zeros\n",
        "\n",
        "$y = [1.1, 0.2, -0.7, 2.4 $\n",
        "\n",
        "2. Compute Loss and Gradientes: We calculate the loss and then backpropagate to find the gradients of loss with respect $A$ and $B$:\n",
        "\n",
        "$Loss = 2.75$\n",
        "\n",
        "Crucially, since $W$ is **frozen** we do not compute its gradient. The gradients are computed only for the trainable parameters:\n",
        "$\\begin{aligned}\n",
        "\\nabla_W \\mathcal{L} &= 0 \\\\\n",
        "\\nabla_A \\mathcal{L} &= \\frac{\\partial \\mathcal{L}}{\\partial A} \\\\\n",
        "\\nabla_B \\mathcal{L} &= \\frac{\\partial \\mathcal{L}}{\\partial B}\n",
        "\\end{aligned}$\n",
        "\n",
        "Via backpropagation, we find the numerical gradientes (values are approximate):\n",
        "\n",
        "$\\nabla_A \\mathcal{L} = \\begin{bmatrix}\n",
        "0.1 & 0.2 & -1.7 & 1.4 \\\\\n",
        "0 & 0 & 0 & 0\n",
        "\\end{bmatrix}$, $\\nabla_B \\mathcal{L} = \\begin{bmatrix}\n",
        "0.01 & -0.01 \\\\\n",
        "0.02 & -0.02 \\\\\n",
        "-0.17 & 0.17 \\\\\n",
        "0.14 & -0.14\n",
        "\\end{bmatrix}$\n",
        "\n",
        "3. Update Parameters: We update $A$ and $B$ using gradient descent. $W$ is not Updated.\n",
        "$\n",
        "\\begin{aligned}\n",
        "A_{\\text{new}} &= A - \\alpha \\cdot \\nabla_A \\mathcal{L} \\\\\n",
        "B_{\\text{new}} &= B - \\alpha \\cdot \\nabla_B \\mathcal{L}\\\\\n",
        "W_{\\text{new}} &= W\n",
        "\\end{aligned}$\n",
        "\n",
        "with alpha = 0.1, the new matrices are:\n",
        "$\n",
        "B_{\\text{new}}A_{\\text{new}} = \\begin{bmatrix}\n",
        "0.999 & 0.001 \\\\\n",
        "-0.002 & 1.002 \\\\\n",
        "0.517 & -0.517 \\\\\n",
        "-1.014 & 1.014\n",
        "\\end{bmatrix} x \\begin{bmatrix}\n",
        "0.09 & 0.18 & 0.47 & 0.26 \\\\\n",
        "-0.1 & -0.2 & 0.0 & 0.1\n",
        "\\end{bmatrix} = \\begin{bmatrix}\n",
        "0.0898 & 0.1796 & 0.4695 & 0.2598 \\\\\n",
        "-0.1004 & -0.2008 & -0.0009 & 0.0997 \\\\\n",
        "0.0982 & 0.1965 & 0.2430 & 0.0827 \\\\\n",
        "-0.1927 & -0.3853 & -0.4766 & -0.1622\n",
        "\\end{bmatrix}$\n",
        "\n",
        "The original weight matrix $W$ remains **completly uncharged**.\n",
        "\n",
        "4. New Effective weight. Finally, we can see how the effective weight matrix has changed due to the updates to $A$ and $B$ only.\n",
        "$\n",
        "W_{\\text{eff}} =\n",
        "\\underbrace{\n",
        "\\begin{bmatrix}\n",
        "1 & 0 & -1 & 2 \\\\\n",
        "0 & 1 & 1 & -1 \\\\\n",
        "2 & -2 & 0 & 0 \\\\\n",
        "1 & 1 & 1 & 1\n",
        "\\end{bmatrix}\n",
        "}_{W \\text{ (Original / Congelado)}}\n",
        "+\n",
        "\\underbrace{\n",
        "\\begin{bmatrix}\n",
        "0.0898 & 0.1796 & 0.4695 & 0.2598 \\\\\n",
        "-0.1004 & -0.2008 & -0.0009 & 0.0997 \\\\\n",
        "0.0982 & 0.1965 & 0.2430 & 0.0827 \\\\\n",
        "-0.1927 & -0.3853 & -0.4766 & -0.1622\n",
        "\\end{bmatrix}\n",
        "}_{B_{\\text{new}}A_{\\text{new}} \\text{ (Adaptación)}}\n",
        "=\n",
        "\\begin{bmatrix}\n",
        "1.0898 & 0.1796 & -0.5305 & 2.2598 \\\\\n",
        "-0.1004 & 0.7992 & 0.9991 & -0.9003 \\\\\n",
        "2.0982 & -1.8035 & 0.2430 & 0.0827 \\\\\n",
        "0.8073 & 0.6147 & 0.5234 & 0.8378\n",
        "\\end{bmatrix}\n",
        "$\n",
        "\n",
        "After just one update, only the small matrices $A$ and $B$ have been modfied, changing the overall behaivor of the layer while keeping the massive original weight matrix $W$ frozen.\n",
        "\n",
        "## How training works (quick recap)\n",
        "\n",
        "1. Forward: compute with $W_{\\text{eff}} = W + BA$\n",
        "2. Compute loss\n",
        "3. Back-propagate gradients only into $A$ and $B$\n",
        "4. Update $A$ and $B$; keep $W$ frozen\n",
        "\n",
        "## Does LoRA add new Layers?\n",
        "\n",
        "No. A LoRA patch lives *inside* an existing `nn.Linear.Layer`\n",
        "\n",
        "* The layer's computation (suring forward pass) is rewritten as\n",
        "\n",
        "$y = (W + BA)x + b,$\n",
        "\n",
        "but the call-graph still contains just the original layer.\n",
        "\n",
        "* $A$ and $B$ are lightweight *matrices*, not brand-new modules.\n",
        "* At inference you can *merge* them once into $W$ and discard the patch: $W$ <- $W$ + $BA$\n",
        "\n",
        "$W_{\\text{eff}} = W + BA\n",
        "with \\underbrace{\n",
        "W\n",
        "}_{Frozen} +\n",
        "\\underbrace{\n",
        "BA\n",
        "}_{trainable, low-rank}\n",
        "$\n",
        "\n",
        "Thus LoRA changes the parameters a layer holds, not the network topology."
      ],
      "metadata": {
        "id": "oYn9lN7h29nj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LoRA Diagram\n",
        "\n",
        "![](https://raw.githubusercontent.com/sebastianperezv/AI_Engineering_Customizing_LLMs_for_Buisness/refs/heads/main/Images/LoRA_Diagram.jpg)"
      ],
      "metadata": {
        "id": "xqlfRwlMdGNu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LoRA Parameter Savings Example\n",
        "\n",
        "Assume:\n",
        "\n",
        "* **LLaMA-7B** contains app 7 billion parameters in total.\n",
        "* We apply LoRA to its linear layers, which contain the vast majority of its parameters. The total number of weights in these layers is app **6.49 billion.**\n",
        "* LoRA rank is fixed at $r = 8$\n",
        "For a linear layer of shape $(kx d)$ LoRA adds\n",
        "\n",
        "$A \\in \\mathbb{R}^{r \\times d}$, $B \\in \\mathbb{R}^{k \\times r}$ -> extra params per layer = $r(k + d)$\n",
        "\n",
        "With a typical layer size of $k = d = 4096$:\n",
        "per layer = $8(4096 + 4096) = 8 x 8192 = 65,536$\n",
        "\n",
        "Assuming we patch 100 of the model's main linear layers (a common practice):\n",
        "$100 x 65,536 = 6.55 million$ parameters.\n",
        "\n",
        "we only are gonna be adding 6.55 million parameters instead of 6.48 billion\n",
        "\n",
        "### Perpective\n",
        "\n",
        "$$\\frac{6.55 \\text{ M}}{6.48 \\text{ B}} \\approx 0.1\\%$$ (of targeted layers),\n",
        "$$ \\frac{6.55 \\text{ M}}{7 \\text{ B}} \\approx 0.094\\% $$ (of the entire model)\n",
        "\n",
        "LoRA therefore tunes about **one-tenth of one percent** of the weights it tiuches and below one-tenth of one percent of the full network-a truly dramatic savings in both memory compute\n",
        "\n",
        "## What does Rank mean in LoRA?\n",
        "\n",
        "Think of the rank $r$ as a **dial** that controls how much freedom the LoRA patch has.\n",
        "\n",
        "**Linear-algebra view.** The **rank** of a matric is the count independent rows or columns, how many directons can cover in space.\n",
        "\n",
        "**LoRA view**. We replace a full (large) update matrix $\\Delta W \\in \\mathbb{R}^{f \\times d}$ in a product of two skinny ones:\n",
        "\n",
        "$\\Delta W = BA$, $A \\in \\mathbb{R}^{r \\times d}$, $B \\in \\mathbb{R}^{k \\times r}$\n",
        "\n",
        "The middle dimension $r$ is the **bottle neck size**-our dial.\n",
        "\n",
        "* **Small** r -> very few parameters, runs fast, but can only make coarse adjustments.\n",
        "\n",
        "* **Large** r -> more parameters and compute, but can learn subtler changes\n",
        "\n",
        "In practice people pick:\n",
        "\n",
        "$$ r \\in \\{4, 8, 16, 32\\} $$\n",
        "\n",
        "chosing a higher value for bigger models or harder tasks.\n",
        "\n",
        "## Sumary\n",
        "\n",
        "* LoRA injects low-rank *matrices*, not new layers.\n",
        "* Only the small patches *(A, B)* are trained; $W$ stays frozen.\n",
        "* Widely used on nn.Layers layers in transformers to enable rapid, memory-efficient adaptation.\n",
        "* Used for fine-tunning."
      ],
      "metadata": {
        "id": "p9v433ImcqbQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Conviene entrenar $B$ y $A$ porque ahorras más del 99% de la memoria y el cómputo, lo que te permite hacer en una tarjeta gráfica casera lo que normalmente requeriría un centro de datos.Aquí tienes la demostración matemática irrefutable de por qué conviene:\n",
        "**1. La Matemática del Ahorro (La comparación brutal)**\n",
        "Imagina una capa típica de un modelo como Llama 2 o Mistral.\n",
        "* Dimensión ($d$): 4096 neuronas de entrada y salida.\n",
        "* Rango ($r$): 8 (un valor estándar en LoRA).\n",
        "**Opción A: Entrenar la matriz original ($W$)**\n",
        "Tienes que entrenar toda la cuadrícula de $4096 \\times 4096$.$$4,096 \\times 4,096 = \\mathbf{16,777,216 \\text{ parámetros}}$$Necesitas calcular y guardar gradientes para 16 millones de números.\n",
        "\n",
        "**Opción B: Entrenar $B$ y $A$ (LoRA)**Tienes dos matrices flacas: $(4096 \\times 8)$ y $(8 \\times 4096)$.$$(4,096 \\times 8) + (8 \\times 4,096) = 32,768 + 32,768 = \\mathbf{65,536 \\text{ parámetros}}$$\n",
        "* Solo calculas gradientes para 65 mil números.\n",
        "\n",
        "**El Resultado:**$$65,536 \\div 16,777,216 \\approx \\mathbf{0.0039}$$¡Estás entrenando solo el 0.39% de los datos originales!\n",
        "\n",
        "**2. ¿Por qué esto \"conviene\" en la práctica?**\n",
        "\n",
        "No es solo que sea \"menos trabajo\", es que rompe la barrera física del hardware.\n",
        "\n",
        "Cuando entrenas, la memoria de tu GPU (VRAM) no se llena por el modelo en sí, se llena por los Estados del Optimizador (la memoria de qué tanto cambiar cada parámetro).\n",
        "* **Sin LoRA:** Necesitas guardar el historial de cambios de 16 millones de parámetros.Consecuencia: Necesitas 80 GB de VRAM (Tarjeta A100 industrial).\n",
        "* **Con LoRA:** Solo guardas el historial de los 65 mil parámetros de $A$ y $B$.\n",
        "* Consecuencia: Cabe en 24 GB de VRAM (Tarjeta RTX 3090/4090 casera o instancia barata de AWS)."
      ],
      "metadata": {
        "id": "xZzOkkqWlk-y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# (Optional) Matrix Multiplication Refresher"
      ],
      "metadata": {
        "id": "10fWSJE8gxie"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's supose we have an equation\n",
        "# y = x1 * w1 + x2 * w2\n",
        "\n",
        "import torch\n",
        "# Input data\n",
        "X = torch.tensor([\n",
        "    [1.0, 2.0]\n",
        "])"
      ],
      "metadata": {
        "id": "6dt_b80shBZy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# weight matrix\n",
        "W_true = torch.tensor([\n",
        "    [3.0, 5.0]\n",
        "])"
      ],
      "metadata": {
        "id": "5vsjbwxlhTQc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We need to transpose W_true in order to multiply it. The shape will change from 1 x 2 -> 2 x 1"
      ],
      "metadata": {
        "id": "vhTZixwihlU9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate targets with Transposed weights\n",
        "# @: this is matrix multiplication\n",
        "y = X @ W_true.T"
      ],
      "metadata": {
        "id": "VLQAgBlxh85T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "x = torch.tensor([[1.0, 2.0]])\n",
        "W = torch.tensor([[3.0, 5.0]])\n",
        "\n",
        "y = x @ W.T\n",
        "print(y)"
      ],
      "metadata": {
        "id": "eNq4wt64ihyd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# VlaueError: mat1 and mat2 shapes cannot be multiplied (1x2 and 1x2)\n",
        "y = x @ W"
      ],
      "metadata": {
        "id": "fGx79rkoi8o-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Understanding LoRA Programatically Part 1\n",
        "\n",
        "We are gonna look at a simple example of how LoRA can actually speed up training and make it more efficient. This is just a quick demostration of a simplified implementation before we do a deep dive.\n",
        "\n",
        "This experiment compares two ways to train a model:\n",
        "\n",
        "* A full tuning\n",
        "* A LoRA tuning\n",
        "\n",
        "The model itself is a simple linear layer that it is learning to perform a multivariate linear regression task."
      ],
      "metadata": {
        "id": "KKxBv2KO70S_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "import torch, torch.nn as nn, torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "#torch.manual_seed(42)"
      ],
      "metadata": {
        "id": "f2df6BqU9i6H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We dont have data so we are going to use synthetic data\n",
        "k, d, r = 128, 128, 32 # k is output, d is input, and r is rank"
      ],
      "metadata": {
        "id": "ZAq3C0aE97l2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create W_base, A_true, B_true, W_true\n",
        "W_base = torch.randn(k, d) # pre-trained frozen weight\n",
        "A_true = torch.randn(r, d)\n",
        "B_true = torch.randn(k, r)\n",
        "W_true = W_base + B_true @ A_true # ground-truth weight (Weff)"
      ],
      "metadata": {
        "id": "ZpN8zE13GL6x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's see the shapes\n",
        "print(W_base.shape) # 128 x 128\n",
        "print(A_true.shape) # 32 x 128\n",
        "print(B_true.shape) # 128 x 32\n",
        "print(W_true.shape) # 128 x 128"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YrB8PXHMG9D6",
        "outputId": "2b01ace5-e18c-4637-a7fb-7b5caca0c756"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([128, 128])\n",
            "torch.Size([32, 128])\n",
            "torch.Size([128, 32])\n",
            "torch.Size([128, 128])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ejemplo: Si tu entrada (Input) es la foto de un auto, el modelo te devolverá un vector (una lista) de 128 números que representan las características de ese auto específico."
      ],
      "metadata": {
        "id": "rY6FnpSdMtoS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# we have 10000 samples and each sample has 128 features\n",
        "N = 10_000\n",
        "X = torch.randn(N, d) # 10000 x 128\n",
        "y = X @ W_true.t() # 10000 x 128\n",
        "print(W_true.t().shape) # 128 x 128\n",
        "print(y.shape) # 10000 x 128 output of the model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C7tbABFxHf-f",
        "outputId": "2a78044e-2626-4d54-c89f-d1600e1c2ea9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([128, 128])\n",
            "torch.Size([10000, 128])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is a multivariate regression thats why the output is 10,000 x 128. When you need to predict the value of a house for example the output would look like 10,000 x 1. So we have 10,000 and each one of them has 128 outputs."
      ],
      "metadata": {
        "id": "InRhigWpJSWo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Understanding LoRA Programatically Part 1"
      ],
      "metadata": {
        "id": "VDlpAu_ka2Na"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Models\n",
        "\n",
        "`class LoRALinear`\n",
        "\n",
        "`self.A = nn.Parameter(0.01 * torch.randn(rank, d))`\n",
        "* 0.01 is core idea of LoRA, so that B matrix multiply by A matrix starts near 0 so the initial output when you multiply B times A is gonna be app equal to the W_frozen. The reason whywe need to be approximately the same is because this prevents large updates and it keeps the gradients and outputs stable early on, and LoRA is about small corrections not replacing the whole frozen weight matrix.\n",
        "> Basically, multiply it by 0.01 will ensure that the multiplication of matrix B by matrix A are gonna be really small numbers so that when you add it to the W_base is not gonna be a huge update.\n",
        "\n",
        "`self.register_buffer('W', W_frozen)`\n",
        "* Guarda la matriz de pesos original (`W_frozen`) en el modelo.\n",
        "* Al usar register_buffer, le dices a PyTorch que estos datos son parte del estado del modelo, pero no son parámetros entrenables"
      ],
      "metadata": {
        "id": "IwgfDizwHkC7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LoRALinear(nn.Module):\n",
        "  def __init__(self, W_frozen, rank): # rank how much parameters we a¿want to tune\n",
        "    super().__init__()\n",
        "    k, d = W_frozen.shape # 128 x 128 it is from W_base, k is output d is input\n",
        "    self.register_buffer('W', W_frozen) # we dont want calculate gradientes for W_frozen (W = W_frozen)\n",
        "    self.A = nn.Parameter(0.01 * torch.randn(rank, d)) # nn.Parameters wraps the tensor a trainable parameter in Pytorch\n",
        "    self.B = nn.Parameter(torch.zeros(k, rank)) # 128 x 32\n",
        "    print(f'W_frozen shape: {W_frozen.shape}') # k, d\n",
        "    print(f'A shape: {self.A.shape}') # r, d\n",
        "    print(f'B shape: {self.B.shape}') # k, r\n",
        "\n",
        "  def forward(self, x):\n",
        "    return x @ (self.W + self.B @ self.A).t()"
      ],
      "metadata": {
        "id": "MJRDpF7iNOFd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`class FullLinear(nn.Module)`\n",
        "\n",
        "Esta clase representa el \"Fine-Tuning\" estándar para comparación.\n",
        "`self.W = nn.Parameter(W_init.clone())`\n",
        "* Aquí clonamos todos los pesos originales y los envolvemos en `nn.Parameter`.\n",
        "* Esto significa que PyTorch intentará entrenar y modificar cada uno de los números de la matriz $128 \\times 128$.\n",
        "\n",
        "> Es mucho más costoso en memoria y cómputo que la versión LoRA, ya que no hay reducción de rango ni parámetros congelados."
      ],
      "metadata": {
        "id": "f0MNZ1fjgWH-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FullLinear(nn.Module):\n",
        "  def __init__(self, W_init):\n",
        "    super().__init__()\n",
        "    self.W = nn.Parameter(W_init.clone())\n",
        "\n",
        "  def forward(self, x):\n",
        "    return x @ self.W.t()"
      ],
      "metadata": {
        "id": "V1HB4LyAd0C2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reminder:\n",
        "\n",
        "Al llamar a super().__init__(), estás diciendo: \"PyTorch, por favor, configura toda la maquinaria interna necesaria de una red neuronal antes de que yo empiece a definir mis capas personalizadas (A y B)\"."
      ],
      "metadata": {
        "id": "stNkxSKLjCfU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Understanding LoRA Programatically Part 2"
      ],
      "metadata": {
        "id": "U445W2tjhUmP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate the models\n",
        "model_lora = LoRALinear(W_frozen=W_base, rank=r)\n",
        "model_full = FullLinear(W_init=W_base)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lFRXOcFihWUP",
        "outputId": "48eb6eb9-8c68-47bd-9625-9f62305ba09f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "W_frozen shape: torch.Size([128, 128])\n",
            "A shape: torch.Size([32, 128])\n",
            "B shape: torch.Size([128, 32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'LoRA trainable params: {sum(p.numel() for p in model_lora.parameters() if p.requires_grad):,}')\n",
        "print(f'Full-FT params: {sum(p.numel() for p in model_full.parameters() if p.requires_grad):,}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nTOtxxjjkv6N",
        "outputId": "7bf2b1c4-47cd-46a3-9c85-bfd6dcc42ff8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LoRA trainable params: 8,192\n",
            "Full-FT params: 16,384\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Training"
      ],
      "metadata": {
        "id": "UomCjO0hlsVj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# just to visualize how to create the shapes\n",
        "idx = torch.randint(0, N, (256, 4))\n",
        "idx.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yLA2zo7zsvmd",
        "outputId": "ef2693f4-9aeb-47fb-c079-fefe33035e51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([256, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, steps=5000, batch=256, lr=1e-2):\n",
        "  opt = optim.Adam(model.parameters(), lr=lr)\n",
        "  mse = nn.MSELoss()\n",
        "  losses = []\n",
        "  for s in range(steps):\n",
        "    idx = torch.randint(0, N, (batch,)) # random number from 0 to 10000 in shape of (256,) in a tensor\n",
        "    # the samples are going to be 256\n",
        "    loss = mse(model(X[idx]), y[idx]) # shape 256 x 128\n",
        "    opt.zero_grad() # resets all gradients of the model parameters to zero\n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "    losses.append(loss.item())\n",
        "  return losses"
      ],
      "metadata": {
        "id": "r9aUDRComfkj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_lora = train(model_lora)\n",
        "loss_full = train(model_full)"
      ],
      "metadata": {
        "id": "nJxqqsdkr-Od"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Plots\n"
      ],
      "metadata": {
        "id": "Fqi77xUGwRK2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make some plots\n",
        "fig, ax = plt.subplots(1, 2, figsize=(12,4))\n",
        "ax[0].plot(loss_full, label='Full-Fine-Tune')\n",
        "ax[0].plot(loss_lora, label=f'LoRA (r={r})')\n",
        "ax[0].set_yscale(\"log\"); ax[0].set_xlabel('Step'); ax[0].set_ylabel('Batch MSE')\n",
        "ax[0].set_title('Training Loss'); ax[0].legend()\n",
        "\n",
        "ax[1].bar(['Fulln(16 384)', 'LoRA\\n(2048)'],\n",
        "          [16_384, r*(k+d)])\n",
        "ax[1].set_ylabel('# trainable weights')\n",
        "ax[1].set_title('Parameter Budget')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show();"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "id": "dmJ8TQNtwbpv",
        "outputId": "26baaaa4-cba8-452c-8a5a-558e02db7969"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x400 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The training loss with LoRA decreases significally fast, because you have fewer parameters, showing how sometimes LoRA is more efficient. This is a simplier task though, if this would have been a more complex task, LoRA would decrease sooner, but when you use the Full Fine-Tune the final loss is gonna be better when you use more parameters.\n",
        "\n",
        "But when you are working with LLM, and have billion of parameters, using LoRA could save companies millions of dollars"
      ],
      "metadata": {
        "id": "wgQCW5Ka21qz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 5) How close to the true ΔW? -------------------------------------\n",
        "with torch.no_grad():\n",
        "  ΔW_true = B_true @ A_true\n",
        "  ΔW_lora = model_lora.B @ model_lora.A\n",
        "  ΔW_full = model_full.W - W_base\n",
        "  mse = lambda a,b: ((a-b)**2).mean().item()\n",
        "  print(f\"ΔW MSE  LoRA : {mse(ΔW_lora, ΔW_true):.2e}\")\n",
        "  print(f\"ΔW MSE  Full : {mse(ΔW_full , ΔW_true):.2e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OaiXYFAn2b1z",
        "outputId": "1781204e-1fef-436e-c086-4aaba694efd3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ΔW MSE  LoRA : 1.22e-12\n",
            "ΔW MSE  Full : 2.04e-06\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bfloat16 vs Float32\n",
        "\n",
        "Using different types of number, instead of using Float32 for various operations we use Bfloat32. This is a tecnique used to improve the training, but it should not confused with quantization, because when you quantize a number or a training you essentially change the **data type** so you change it for example from *float32* to *integer*.\n",
        "\n",
        "With mixed precision training, or when we use **Float32 vs Bfloat16** during training we are not changing the type from Float to integer, we are just changing to a different type of Float. Float32 is able to hold a lot of information but it takes up a lot more memory then for example Bfloat16 (16 bit)\n",
        "\n",
        "## 1. Understanding Floating-Point Components\n",
        "\n",
        "A floating-point number is represented in a form of scientific notation, typically composed of three parts:\n",
        "\n",
        "* **Sign**: A single bit indicating if the number is positive (0) or negative(1)\n",
        "* **Exponnent**: Determines the number's magnitude or range. It tells the computer the range the number is, this number could be between this and this value.\n",
        "* **Mantissa**: Determines the number's precision. More mantissa bits mean higher precision.\n",
        ">Imagine you have two rulers, both one meter long. Their range is the same (0 to 1\n",
        "meter).\n",
        "Float32 is like a ruler with millimeter markings. It’s very precise. You can accurately\n",
        "measure 51.1 cm, 51.2 cm, etc.\n",
        "Bfloat16 is like a ruler that only has markings for every full centimeter. It has the same\n",
        "length (range), but you can’t measure with the same precision. You can see something is\n",
        "about 51 cm, but you can’t tell if it’s 51.1 or 51.2.\n",
        "This is the trade-off: bfloat16 keeps the same measurement length (range) as float32 but\n",
        "uses fewer markings (lower precision) to save space.\n",
        "> This is why during training you can use Bfloat16 because it is actually quite similar to how a float32 behaves.\n",
        "\n",
        "## 2. Visual comparison: Float32 vs. Bfloat16\n",
        "\n",
        "The key difference between the standard 32-bit float (Float32) and the 16 bit brain float (Bfloat) is how they allocate their bits between the exponent and the mantissa.\n",
        "\n",
        "### 2.1 Flaot32 (single Precision)\n",
        "\n",
        "Float32 uses 32 bits to offer a balance of high precision and a wide dynamic range.\n",
        "\n",
        "* Total bits: 32\n",
        "* Layout: 1 sign bit, 8 exponent bits, 23 mantissa bits\n",
        "\n",
        "S EEEEEEEE MMMMMMMMMMMMMMMMMMMMMMM\n",
        "\n",
        "### 2.2 Bfloat16 (brain float)\n",
        "\n",
        "Bfloat16 uses 16 bits. It was designed for AI and ML, where a wide range is morecritical than high precision.\n",
        "\n",
        "* Total bits: 16\n",
        "* Layout: 1 sign bit, 8 exponent bits, 7 matissa bits\n",
        "\n",
        "S EEEEEEEE MMMMMMM\n",
        "\n",
        "## 3. Key takeaways\n",
        "\n",
        "* **Range is Identical**: Both formats use 8 exponent bits. This means they can represent\n",
        "the same enormous range of numbers (from approx. 1.2 × 10−38 to 3.4 × 1038). Bfloat16\n",
        "does not sacrifice the ability to handle very large or very small values.\n",
        "* **Precision is the Trade-Off**: The difference lies in the mantissa. Float32’s 23 bits provide high precision (many significant digits), while Bfloat16’s 7 bits offer lower precision.\n",
        "This trade-off makes Bfloat16 half the size, leading to significant memory savings and\n",
        "faster computations in hardware that supports it, which is ideal for machine learning\n",
        "workloads.\n",
        "\n",
        "> So, Bfloat16 is not as precise but for our calculations it turns out that when we use Bfloat16 we get a significant amount of speed during training and you lose only very litle data in the precision trade-off.\n"
      ],
      "metadata": {
        "id": "DiFY2wZg4WBk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Comparing Bfloat16 Vs Float32 Programatically"
      ],
      "metadata": {
        "id": "YmWvm2X9m_x5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "S4GS_kQCt7CM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a large random tensor with 1 billion elements\n",
        "# This simulates the size of a large model's parameters\n",
        "num_elements = 1_000_000_000 # 1 billion elements\n",
        "type(num_elements)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R4oNIz1J18gB",
        "outputId": "16e7851c-e540-4847-c8ed-1652cb209b62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "int"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tensor in standard float32 format\n",
        "tensor_fp32= torch.randn(num_elements, dtype=torch.float32)"
      ],
      "metadata": {
        "id": "NBnnPcrf2Xy-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# See the shape, type\n",
        "print(f\"Tensor shape: {tensor_fp32.shape}\")\n",
        "print(f\"Tensor type: {type(tensor_fp32)}\")\n",
        "print(f\"Tensor data type in the tensor: {tensor_fp32.dtype}\")\n",
        "print(f\"See the tensor: {tensor_fp32}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oe0UhXB02nvt",
        "outputId": "6b8f6066-886c-47fd-96f9-f056e02499e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor shape: torch.Size([1000000000])\n",
            "Tensor type: <class 'torch.Tensor'>\n",
            "Tensor data type in the tensor: torch.float32\n",
            "See the tensor: tensor([ 0.0468, -0.0229,  1.5815,  ..., -0.4454,  1.7068,  1.1766])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tensor in bfloat16 format\n",
        "# we create it in fp32 first and then convert it, which is a common practice\n",
        "tensor_bf16 = tensor_fp32.to(dtype=torch.bfloat16)"
      ],
      "metadata": {
        "id": "He7oQxAP2-sg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# See the shape, type\n",
        "print(f\"Tensor shape: {tensor_bf16.shape}\")\n",
        "print(f\"Tensor type: {type(tensor_bf16)}\")\n",
        "print(f\"Tensor data type in the tensor: {tensor_bf16.dtype}\")\n",
        "print(f\"See the tensor: {tensor_bf16}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6tWOOJBs4nTL",
        "outputId": "f1ee528e-7da6-4364-ec84-538bc1d40c59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor shape: torch.Size([1000000000])\n",
            "Tensor type: <class 'torch.Tensor'>\n",
            "Tensor data type in the tensor: torch.bfloat16\n",
            "See the tensor: tensor([ 0.0469, -0.0229,  1.5781,  ..., -0.4453,  1.7031,  1.1797],\n",
            "       dtype=torch.bfloat16)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reminder:\n",
        "\n",
        "1. El Cálculo (Bits a Bytes)\n",
        "torch.float32 significa \"Floating Point de 32 bits\".\n",
        "\n",
        "* Las computadoras almacenan la memoria en Bytes, no en bits individuales.\n",
        "\n",
        "* Sabemos que 1 Byte = 8 bits.\n",
        "\n",
        "2. ¿Por qué es importante en tu código?En tu script estás creando un tensor con 1 billón (1,000,000,000) de elementos.Gracias a element_size(), puedes calcular la memoria RAM exacta que consumirá esa variable:\n",
        "* Cantidad: 1,000,000,000 elementos.* Peso unitario: 4 bytes.\n",
        "* Total: 4,000,000,000 bytes $\\approx$ 4 GB de RAM.\n",
        "\n",
        "Comparación con bfloat16\n",
        "\n",
        "Si ejecutaras tensor_bf16.element_size(), te retornaría 2.\n",
        "* bfloat16 son 16 bits.\n",
        "* $16 / 8 = 2 \\text{ bytes}$.\n",
        "* Tu tensor de 1 billón de elementos en este formato solo ocuparía 2 GB (la mitad).Por esto hacemos Quantization (QLoRA): pasamos de 4 bytes por parámetro a 0.5 bytes (4-bit), reduciendo el modelo 8 veces su tamaño.\n"
      ],
      "metadata": {
        "id": "9ZGIDnDM7WSo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_fp32.element_size(), tensor_bf16.element_size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r5vzPBS16XRt",
        "outputId": "229044a1-92fc-4b67-a423-d2f2b4b2b218"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the memory size in Gigabytes (GB)\n",
        "size_fp32_gb = tensor_fp32.element_size() * tensor_fp32.nelement() / (1024**3)\n",
        "size_bf16_gb = tensor_bf16.element_size() * tensor_bf16.nelement() / (1024**3)"
      ],
      "metadata": {
        "id": "qd8vlyqi4pmM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Size of float32 tensor: {size_fp32_gb:.2f} GB\")\n",
        "print(f\"Size of bfloat16 tensor: {size_bf16_gb:.2f} GB\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bGG-3MWl6GzH",
        "outputId": "5163873f-46f8-41ad-9b42-aa525b9d4081"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of float32 tensor: 3.73 GB\n",
            "Size of bfloat16 tensor: 1.86 GB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# A number with lots of a decimal detail\n",
        "original_number = 3.141592653523452345235235234523452352345234523452352345234"
      ],
      "metadata": {
        "id": "DWFm5fO06UHX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Store it in both formats\n",
        "num_fp32 = torch.tensor(original_number, dtype=torch.float32)\n",
        "num_bf16 = torch.tensor(original_number, dtype=torch.bfloat16)"
      ],
      "metadata": {
        "id": "qWdH4he4-GLA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Original Number: {original_number}\")\n",
        "print(f\"Stored as float32: {num_fp32.item()}\")\n",
        "print(f\"Stored as bfloat16: {num_bf16.item()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Tham649-Ywe",
        "outputId": "af5f4764-2a1f-490c-ea84-d4bed308c2fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Number: 3.1415926535234524\n",
            "Stored as float32: 3.1415927410125732\n",
            "Stored as bfloat16: 3.140625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The precision is not as good as it is with float32"
      ],
      "metadata": {
        "id": "ld26Kar9_Epe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import time"
      ],
      "metadata": {
        "id": "PtkfC79T-0R-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# set device agnostic code\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "tZrr603aBNoB",
        "outputId": "c2797a49-7c44-4396-81cc-aa3af0d4b1a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# this cell is just to see something\n",
        "matrix_size = 4096\n",
        "a = torch.randn(matrix_size, matrix_size, device=device)\n",
        "a.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nyHaDHvmEM1Q",
        "outputId": "916c36d6-9244-46ef-d0d3-af0ab3a22e53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4096, 4096])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure we are using a GPU\n",
        "if not torch.cuda.is_available():\n",
        "  print('Please enable GPU in Runtime -> change runtime type')\n",
        "else:\n",
        "  # Create large matrices on the GPU\n",
        "  matrix_size = 16000\n",
        "  a = torch.randn(matrix_size, matrix_size, device=device)\n",
        "  b = torch.randn(matrix_size, matrix_size, device=device)\n",
        "\n",
        "  # Time the float32 multiplication\n",
        "  start_time_fp32 = time.time()\n",
        "  torch.matmul(a, b)\n",
        "  end_time_fp32 = time.time()\n",
        "  print(f'Time for float32 multiplication: {end_time_fp32 - start_time_fp32:.4f} seconds')\n",
        "\n",
        "  # Convert matrices to bfloat16\n",
        "  a_bf16 = a.to(torch.bfloat16)\n",
        "  b_bf16 = b.to(torch.bfloat16)\n",
        "\n",
        "  # time the bf float multiplication\n",
        "  # we use torch.cuda.amp.autocast to ensure hardware acceleration is used\n",
        "  with torch.cuda.amp.autocast(dtype=torch.bfloat16):\n",
        "    start_time_bf16 = time.time()\n",
        "    torch.matmul(a, b)\n",
        "    end_time_bf16 = time.time()\n",
        "    print(f'Time for bfloat16 multiplication: {end_time_bf16 - start_time_bf16:.4f} seconds')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GZ-MycWZBeQC",
        "outputId": "e5792538-7005-4bc0-cb3b-8d1338b5a45c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for float32 multiplication: 0.0901 seconds\n",
            "Time for bfloat16 multiplication: 0.0188 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-4124848313.py:22: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(dtype=torch.bfloat16):\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "By using bloat16 you are gonna use less compute and capacity that it is almost worth it to use bfloat 16 vs floating32"
      ],
      "metadata": {
        "id": "xj2VCujiHVzW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setting up the QLoRA Training Script with Mixed Precision & Double Quantization\n",
        "\n",
        "We are gonna start writing our python script. Let's save it on the script folder. The script file is goingto be called as \"run.clm.py\""
      ],
      "metadata": {
        "id": "v-aua7InBv90"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setting up Imports and Libraries for the Train Script"
      ],
      "metadata": {
        "id": "wcByHJNZsvJB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os # interact with the operating system\n",
        "import argparse # we are pssing the hyperparamters, source_dir, etc\n",
        "\n",
        "from transformers import (\n",
        "    AutoModelForCasualLm, # this allows us to load any casual llm model through the transformer library\n",
        "    AutoTokenizer, # this handles text tokenization\n",
        "    set_seed, # for reproducibility\n",
        "    default_data_collator, # batches data automatically\n",
        "    BitsAndBytesConfig, # Used for 4 bit quantized model loading\n",
        "    Trainer, # high level training API\n",
        "    TrainingArguments # Better communication with the trainer through the trainer arguments\n",
        ")\n",
        "\n",
        "from datasets import load_from_disk # loads a huggingface dataset saved on disk. So when we trained the model we tell where the dataset is\n",
        "\n",
        "import torch\n",
        "\n",
        "import bitsandbtytes as bnb # thats for efficient 4 bit training\n",
        "from huggingface_hub import login, HfFolder # this is to fetch your huggingface hub token and login"
      ],
      "metadata": {
        "id": "Q_WFi-RVauky"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Argument Parsing Function Part 1\n",
        "\n",
        "We are going to create the `parse_arg()` which is gonna pass the arguments we send from the notebook in to our train script.\n",
        "\n",
        "Some key points:\n",
        "\n",
        "`gradient_check()`:\n",
        "\n",
        "Is a tecnique to save a significat amount of gpu memory during model training, at a cost of a small increase in training time. When you train deep neural network your GPU need to store all the intermediate activations which are the results of every layer during the forward pass, because this are going to be needed later on to compute the gradients for backpropagation during the backward pass, and for very large models like LLMs that has billions of parameters this eats up a lot of gpu memory and sometimes the model does not fit on the gpu memory. And usualy what happens is the model's transformers blocks like the attention layers the MLP layers are the one that get gradient check pointed.\n",
        "\n",
        "When you have the forward pass the model compute the full forward pass, however it only saves activations at selected major activation checkpints. So activations for layers between checkpoints are not saved to memory.\n",
        "\n",
        "When the backward pass needs an activation for a layer without a saved activation, it simply recomputes the forward pass starting from the nearest previous checkpoint up to that layer.\n",
        "\n",
        "Basically, when we do the forward pass there are a lot of activations that we save, but dont save all of them, we only saves the ones at major checkpoints, after an attention layer, MLP layer, those layers that took a lot of computation. Now, when the model is doing backpropagation to calculate the gradients, some of this activation will be missing so what it does on the fly, it recalculates the forward pass for that part where the activations re messing, and it simply recomputes the gradients.\n",
        "\n",
        "-> So the additional training time comes because it will do the forward pass several times when it is not at a major checkpoint but that means it doesnt have to save all the activations from the forward in one.\n",
        "\n",
        "Thats make it cheaper for us, because although the training time will increse by 10%, 20% because we use less GPU memory we dont need as powerful of a GPU, so that means we actually save money by selecting a smaller gpu even though it takes a little more time to train.\n",
        "\n",
        "## Heads up...\n",
        "\n",
        "Not all of the arguments are passed by the LLM notebook such as `gradient_checkpointing`, that is why we set default values\n",
        "\n"
      ],
      "metadata": {
        "id": "BnHbfQ4Ns8mD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_arge():\n",
        "  parser = argparse.ArgumentParser()\n",
        "\n",
        "  # add the stuff to the parser\n",
        "  parser.add_argument(\n",
        "      \"--model_id\",\n",
        "      type = str,\n",
        "      help = \"Model id used for training\"\n",
        "  )\n",
        "\n",
        "  parser.add_argument(\n",
        "      \"--dataset_path\",\n",
        "      type = str,\n",
        "      default = 'lm_dataset',\n",
        "      help = 'path to dataset'\n",
        "  )\n",
        "\n",
        "  parser.add_argument(\n",
        "      \"--hf_token\",\n",
        "      type = str,\n",
        "      default = HfFolder.get_token(),\n",
        "      help = \"hf token\"\n",
        "  )\n",
        "\n",
        "  parser.add_argument(\n",
        "      \"--epochs\",\n",
        "      type = int,\n",
        "      default = 3,\n",
        "      help = \"number of epochs to run for\"\n",
        "  )\n",
        "\n",
        "  parser.add_argument(\n",
        "      \"--per_device_train_batch_size\",\n",
        "      type = int,\n",
        "      default = 1,\n",
        "      help = \"batch size to use per training\"\n",
        "  )\n",
        "\n",
        "  parser.add_argument(\n",
        "      \"--lr\",\n",
        "      type = float,\n",
        "      default = 5e-5,\n",
        "      help = \"learning rate to use for training\"\n",
        "  )\n",
        "\n",
        "  parser.add_argument(\n",
        "      \"--seed\",\n",
        "      type = int,\n",
        "      default = 91,\n",
        "      help = \"seed to use for training\"\n",
        "  )\n",
        "\n",
        "  parser.add_argument(\n",
        "      \"--gradient_checkpointing\",\n",
        "      type = bool,\n",
        "      default = True,\n",
        "      help = \"Use or not use gradient checkpointing\"\n",
        "  )\n",
        "\n",
        "  parser.add_argument(\n",
        "      \"--bf16\",\n",
        "      type = bool,\n",
        "      default = True if torch.cuda.get_device_capability()[0] == 8 else False,\n",
        "      help = \" Whether to use bf16 or not\"\n",
        "  )\n",
        "\n",
        "  parse.add_argument(\n",
        "      \"--merge_weights\",\n",
        "      type = bool,\n",
        "      default = True,\n",
        "      help = \"Whether to merge LoRA weights with the base model's weights\"\n",
        "  )\n",
        "\n",
        "  args, _ = parser.parse_known_args()\n",
        "\n",
        "  if args.hf_token:\n",
        "    print(\"logging into hf hub with token\")\n",
        "    loging(token=args.hf_token)\n",
        "\n",
        "  return args"
      ],
      "metadata": {
        "id": "3fQ5P-TJs-hC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Understanding Trainable Parameters Caveats\n",
        "\n",
        "We are gonna write a function that helps us tell how many trainable parameters our model is going to have.\n",
        "\n",
        "`use_4bit=False`\n",
        "\n",
        "The reason why the use_4bit is False is because of the parameters were actually training the LoRA adopters, arent 4 bit. They are going to behandled using bloat 16. We do load and save the model with quantizatio, with 4 bit weights but we are not gonna be training this weights, because when we traine the model we are gonna be using bflaot16.\n",
        "\n",
        "`trainable_params = 0` and `all_param = 0`\n",
        "\n",
        "We start with 0 for both of them, because we have paramaeters that are not trainable, and then we find which one of the parameters are trainable.\n",
        "\n",
        "`for -, param in model.named_parameters():`\n",
        "\n",
        "we loop through all the named parameters in the model, so each param that we loop through is a Tensor, for example it is a layer weights matrix or a bias vector. We are not looping through 7 billion parameters. Eas of these param is a tensor or a weight matrix.\n",
        "\n",
        "`if num_params == 0 and hasattr(param, \"ds_numel\"):\n",
        "      num_params = params.ds_numel`\n",
        "* numel(): Number of Elements\n",
        "> Si una matriz (capa) tiene dimensiones $100 \\times 100$, numel() devuelve $10,000$. Es el conteo bruto de \"neuronas\" en esa capa.\n",
        "\n",
        "If we are using DS03 and the weights are intialized empty, then there is a special case.\n",
        "\n",
        "DSnuml essentially it's a memory optimization technique and when we use this deep seed 0 stage3, it may create empty tensors\n",
        "\n",
        "¿Por qué un parámetro tendría tamaño 0? Esto sucede cuando usas una tecnología llamada DeepSpeed ZeRO-3 (Zero Redundancy Optimizer).\n",
        "\n",
        "* El Problema: Cuando entrenas modelos gigantes en varias GPUs, a veces el modelo es tan grande que no cabe en una sola tarjeta.\n",
        "\n",
        "* La Solución (ZeRO-3): DeepSpeed \"parte\" el modelo en pedacitos y los reparte entre las GPUs.\n",
        "\n",
        "* El Efecto: Si estás en la GPU #1 y preguntas por el tamaño de una capa que está guardada en la GPU #2, tu GPU la ve como \"vacía\" (tamaño 0) porque no la tiene cargada en su RAM local.\n",
        "\n",
        "* La Corrección: Aunque el tamaño local sea 0, el atributo ds_numel (DeepSpeed Number of Elements) guarda el dato real de cuánto pesa esa capa globalmente. Este if asegura que contemos el tamaño real del modelo, incluso si está fragmentado en varios servidores.\n"
      ],
      "metadata": {
        "id": "HnCwtbBiJSGH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def trainable_parameters(model, use_4bit=False):\n",
        "\n",
        "  trainable_params = 0\n",
        "  all_param = 0\n",
        "\n",
        "  for _, param in model.named_parameters():\n",
        "    num_params = param.numel() # number of params\n",
        "\n",
        "    if num_params == 0 and hasattr(param, \"ds_numel\"):\n",
        "      num_params = param.ds_numel\n",
        "\n",
        "    all_param += num_params\n",
        "\n",
        "    if param.requires_grad:\n",
        "      trainable_params += num_params\n",
        "\n",
        "  if use_4bit:\n",
        "    trainable_params /= 2\n",
        "\n",
        "  print(\n",
        "      f\"all params: {all_param:,d} || trainable params: {trainable_params:,d} || trainable%: {100 * trainable_params/all_param}\"\n",
        "  )"
      ],
      "metadata": {
        "id": "ndi71riSKs9C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction to Quantization\n",
        "\n",
        "The important key here is memory efficient at scale.\n",
        "\n",
        "When you fine tuning a 7 billion parameter model, storing all those weights in full precision with floating poit number like float 16, float 32, would require immense memory. That's why we use INT4, because it reduces memory 70% 75%, but there is a crucial part. INT4 quantization doesnt just store 4 bit integers it also stores this numbers called scaling factores that are floating point numbers. And those scaling factors tell us how to convert those INT 4 integers back to the orignial range. This is important because when we train a model we can't train it with INT4, the precision would be way off and the gradients would be all over the place.\n",
        "\n",
        "When you save a model with INT4 weights, you also save the scalling factors, which are these small numbers that allow us to convert the INT4 weights back to floating poit numbers, they wont  be exactly like how they were when you originally saved from floating point numbers to integers, but they are going to be very close enough. This allows us to basically reconstruct the INT4 weights back to a floating precision-based weights.\n",
        "\n",
        "During training or fine-tuinig, we cant do math with int 4 weights because the precision is too low,so every time we need to compute something, we take those int 4 values, we multiply by their scaling factor to de-quantize them back to, in our case, Bfloat16, we do the computation with the Lora adapters, which are the A and B matrices, which are also in Bfloat 16 and then we throw away the temprary Bfloat16 values for the original weights. And so the original int 4 weights and their scalling factors stay frozen in memory.\n",
        "\n",
        "## To conclude\n",
        "\n",
        "You get the memory footprint of INT 4 storage integers plus the scaling factores, but you you also get the numerical stability of Bfloat 16 computation.\n",
        "\n",
        "So without this trick, you couldnt fine-tune large models on consumer GPUs.\n",
        "\n",
        "## QLoRA: Simple Flow\n",
        "\n",
        "1. Loading\n",
        "\n",
        "* Base model: INT4\n",
        "* LoRA Adapters: BFLOAT16 (Two smaller matrices A and B)\n",
        "\n",
        "2. Training (Forward Pass)\n",
        "\n",
        "* INT4 Weights -> dequantize -> BFLOAT16 + LoRA = Output\n",
        "\n",
        "> INT4 weights temporarity converted to BFLOAT16 for computation only\n",
        "\n",
        "3. Saving Final Model\n",
        "\n",
        "INT4 Base -> dequantize -> FP16 + LoRA = Final model: FP16\n",
        "\n",
        "> Key point: INT4 is only or storage/memory savings. All actual math happens in BFLOAT16.\n",
        "\n",
        "### What you need to understand is that...\n",
        "\n",
        "You load the model, the integer 4-based weights, with their integer scaling numbers.\n",
        "\n",
        "INT4 weights temporarity converted to BFLOAT16 for computation only, and the we can simply add the Bfloat16 LoRA to is as well, and we get the final output. Rememer the scaling factors are what allows to dequantize the info weights.\n",
        "\n",
        "When we save the model, we essentially look and take at the INT4 weights, we dequantize thme to bfloat 16 or normal floating point 16 bits, we add to it the LoRA adapters, and then we save the mode in FP16.\n",
        "\n",
        "## Note about quantization\n",
        "\n",
        "Quantization actually cahnges the datatype to integers like int8 or int4. Bfloat16 is when you have reduce precision floating point training, and that's when the training is still done infloates but in a reduced precision. So, we do convert weights from float32 or float 16 into int8 or int4, when you load or save the model, but during forward computation weights are dequantized to bfloat16 for the math operations.\n"
      ],
      "metadata": {
        "id": "BsRQA2aExRr-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "El truco de ingeniería es la Cuantización por Bloques **(Block-wise Quantization)**:\n",
        "* Agrupamos los pesos en bloques (por ejemplo, grupos de 64 pesos).\n",
        "* Esos 64 pesos comparten un solo scaling factor en Float32.\n",
        "**El ahorro es brutal:**\n",
        "* 64 pesos en INT4 = $64 \\times 4 \\text{ bits} = 256 \\text{ bits}$.\n",
        "* 1 scaling factor en FP32 = $32 \\text{ bits}$.\n",
        "* Total: 288 bits.\n",
        "* (Si fuera todo en FP16 original: $64 \\times 16 = 1024 \\text{ bits}$)."
      ],
      "metadata": {
        "id": "yQtAKAf1TDBK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Identifying Trainable Layers for LoRA\n",
        "\n",
        "\n",
        "We are going to create findAllLinear function. And we will use the list that this function returns to us to tell LoRA which Layers to inject trainable adapters into, or trainable weights. So essentially we are gonna find all the Linear Layers to which we can insert our smaller matrices.\n",
        "\n",
        "`bnb.nn.Linear4bit`:\n",
        "\n",
        "Remember that we have loaded the model (weights) in 4 bits so that is the Lienar Layer we need to search, which is quantized layer of type bnb.nn.Lienar4bit since that is where LoRA can be applied. For matrix operation we are gonna transform it in float16\n",
        "\n",
        "Helps destinguish which are this linear layer we can inject LoRA adapters, the smaller matrices that we can multiply and then add to the frozen weight matrix."
      ],
      "metadata": {
        "id": "hxS8CGCFiyDK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Esta función es tu detector de metales automático. Su trabajo es escanear todo el edificio del modelo (Mistral) y marcar con una \"X\" todas las paredes donde se puede hacer la obra (inyectar LoRA).Específicamente, hace lo siguiente:\n",
        "1. El Escaneo (El Loop) Recorre cada rincón del modelo, revisando capa por capa (`model.named_modules()`).\n",
        "2. El Filtro (El `isinstance`) Aquí aplica lo que acabas de aprender.\n",
        "* Mira una capa y pregunta: \"¿Eres una ecuación lineal ($ax+b$) comprimida en 4 bits?\" (`bnb.nn.Linear4bit`).\n",
        "* Si la respuesta es SÍ, la marca como candidata.\n",
        "* Si es una capa de normalización o activación, la ignora.\n",
        "3. La Limpieza de NombresLos nombres internos de PyTorch son largos y feos, tipo: `model.layers.0.self_attn.q_proj`.\n",
        "* La función corta todo eso y se queda solo con el \"apellido\" importante: `q_proj`, `v_proj`, `gate_proj`, etc.\n",
        "* Usa un `set()` para no tener repetidos (porque `q_proj` aparece en cada una de las 32 capas del modelo, pero solo necesitamos el nombre una vez).\n",
        "4. La Regla de Seguridad (`lm_head`)\n",
        "Al final, verifica si marcó la \"lm_head\" (la última capa lineal que decide qué palabra sale).\n",
        "* Acción: Si está en la lista, la borra.\n",
        "* Razón: En QLoRA, tocar la capa de salida suele causar problemas matemáticos. Queremos que el modelo aprenda a razonar mejor (capas internas), no solo a cambiar la última palabra.\n",
        "\n",
        "Resultado Final (Output)\n",
        "\n",
        "La función te devuelve una lista limpia, por ejemplo:`['q_proj', 'up_proj', 'o_proj', 'k_proj', 'down_proj', 'gate_proj', 'v_proj']`\n",
        "¿Para qué sirve esto?Le entregas esta lista a la configuración de LoRA (LoraConfig) y le dices: \"Toma, pon adaptadores en todas estas, no quiero tener que escribirlas a mano una por una\"."
      ],
      "metadata": {
        "id": "rx2jKroZUyWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def find_all_linear_names(model):\n",
        "  \"\"\"\n",
        "  This will detect which layer to inject LoRA into.\n",
        "  \"\"\"\n",
        "\n",
        "  lora_module_names = set()\n",
        "\n",
        "  for name, module in model.named_module():\n",
        "    if isinstance(module, bnb.nn.Linear4bit): # on the fly we will convert them to floatin pointweights\n",
        "      names = names.split(\".\")\n",
        "      lora_module_names.add(names[0] if len(names) == 1 else names[-1])\n",
        "\n",
        "  if \"lm_head\" in lora_module_names:\n",
        "    lora_module_names.remove(\"lm_head\")\n",
        "\n",
        "  return list(lora_module_names) # example output['q_proj', 'v_proj']"
      ],
      "metadata": {
        "id": "7lHPpyhDxcm3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the upcoming videos we are gonna be uploading the model from the hugging face hub with `bnb.nn.Linear4bit`"
      ],
      "metadata": {
        "id": "CDp2OJJXZpSj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setting up Parameter Efficient Fine Tuning\n",
        "\n",
        "We are going to create `create_peft _model()`, this function is gonna be responsible for a lot optimization for our model, so it will inject the LoRA adaptares into the quantized model, it will enable gradient checking and adjust the datype where appropiate. Remeber to use bfloat 16.\n",
        "\n",
        "`TaskType`:\n",
        "\n",
        "Tells the pfet, or the parameter efficient fine tuning from which we just imported from and which we can then use when we train a model. It tells the task that you are fine tuning the model. Here we are gonna have to specify that we will use casual LLM which is a decoder only, which are like ChatGPT for example.\n",
        "\n",
        "`prepare_model_for_kbit_trainig`\n",
        "\n",
        "this makes 4bit models trainable.\n",
        "\n",
        "`from pfet.tuners.lora import loralayer`\n",
        "\n",
        "This is going to be used to identify Lora-injected modules later on.\n",
        "\n",
        "`lora_alpha = 16`\n",
        "\n",
        "It is a scalling factor that multiplies the LoRA adapter output before it is added to the frozen weight. Alpha controlls how strongly LoRA updates influence the model. This is for avoiding overfitting. This is for how much we want to update the weight, so we are trying to not make it as agresive.\n",
        "\n",
        "La relación $r$ y $\\alpha$:El impacto de los adaptadores se escala mediante la fórmula: $\\Delta W \\times \\frac{\\alpha}{r}$.\n",
        "* Aquí tienes $16 / 64 = 0.25$.\n",
        "* Significa que las actualizaciones de LoRA se suavizan (se multiplican por 0.25) antes de sumarse. Esto ayuda a que el entrenamiento sea más estable y no \"rompa\" el conocimiento previo del modelo bruscamente.\n",
        "\n",
        "`mix_precision_training`\n",
        "\n",
        "this will speed up training with very good accuracy.\n",
        "\n",
        "`model = get_peft_model(model, pfet_conig)`\n",
        "\n",
        "Este es el momento exacto donde el modelo cambia.\n",
        "Antes de esta línea, tenías un modelo Mistral normal (comprimido). Después de esta línea, tienes un modelo híbrido con matrices $A$ y $B$ pegadas a todas las capas lineales que encontró tu función buscadora.\n",
        "\n",
        "\n",
        "`if \"norm\" in name`\n",
        "\n",
        "if the layers whose names containing norm like layer norm, or RMS norm those are numerically sensitive and should stay in float32 for stability. Casting them to lower precision like BF16 could cause training instability.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "lUGBDzyGQ7vG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Remember: we are not training anything in 4 bit, we are loading the model and during training they are in 4bit but whenever those specific weights need any matrix multiplication or matrix operation on them it will convert it on the fly to a Floating point number."
      ],
      "metadata": {
        "id": "dVqOP4dpVumw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_peft_model(model, gradient_checkpointing = True, bf16 = True):\n",
        "  \"\"\"\n",
        "  This function is going to set up the LoRA config and also\n",
        "  implement mix precision training.\n",
        "  \"\"\"\n",
        "\n",
        "  from peft import (\n",
        "      get_peft_model,\n",
        "      LoraConfig, # defines the LoRA injection parameters\n",
        "      TaskType,\n",
        "      prepare_model_for_kbit_training\n",
        "  )\n",
        "\n",
        "  from peft.tuners.lora import loralayer\n",
        "\n",
        "  model = prepare_model_for_kbit_training(\n",
        "      model, use_gradient_checkpointing=gradient_checkpointing\n",
        "  )\n",
        "\n",
        "  # Enabling gradient_checkpointing if it is requested\n",
        "  if gradient_checkpointing:\n",
        "    model.gradient_checkpointing_enable()\n",
        "\n",
        "  # Implement LoRA Configuration and Mixed Precision Training\n",
        "  modules = find_all_linear_names(model)\n",
        "  print(f\"Found {len(modules)} modules to quantize: {modules}\")\n",
        "\n",
        "  pfet_config = LoraConfig(\n",
        "      r = 64,\n",
        "      lora_alpha = 16,\n",
        "      target_modules = modules, # La lista automática que creamos antes ('q_proj', etc.)\n",
        "      lora_dropout = 0.1,\n",
        "      bias = \"none\",\n",
        "      task_type = TaskType.CAUSAL_LM\n",
        "  )\n",
        "\n",
        "  model = get_peft_model(model, pfet_conig)\n",
        "\n",
        "  for name, module in model.named_modules():\n",
        "    if isinstance(module, LoraLayer):\n",
        "      if bf16: # set true above\n",
        "        module = module.to(torch.bfloat16) # here we are converting the LoraLayer into bf16 for faster computation and lower memeory usage\n",
        "\n",
        "    if \"norm\" in name:\n",
        "      module.to(torch.float32)\n",
        "\n",
        "    if \"lm_head\" in name or \"embed_tokens\" in name:\n",
        "      if hasattr(module, \"weight\"):\n",
        "        if bf16 and module.weight.dtype == torch.float32:\n",
        "          module = module.to(torch.bfloat16)\n",
        "\n",
        "  model.print_trainable_parameters()\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "_CG7J74tR139"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Understanding Double Quantization\n",
        "\n",
        "Remember that quantization compresses neural networks from 32 bit floats to smaller flots like 4 bit integer to save memory. But you need scalling factors, which are floats, to converting back to useful weights during our process, whatever we are doing inference or training, and double quantizations go even more further, it also compresses those scaling factors from float to integers, but to turn those compress scale factors back into usuable floats you need new scaling factores, those are the **Meta Scales**.\n",
        "\n",
        "So basically, it is like compressing the compression parameters. And you still need some float parameters and these meta scales must stay as floats, but you need far fewer o them. So one meta scale per large block of thousand of weights instead of one scale per small group of, for example, 128 weights.\n",
        "\n",
        "## Double Quantization Process\n",
        "\n",
        "*Post-training quantization Process*\n",
        "\n",
        "1. Trained Model (FP32 weights)\n",
        "2. Quantize Weights (4-bit integers)\n",
        "3. Quantize Scales (8-bit integers)\n",
        "\n",
        "> What gets saved:\n",
        "Quantized weights + Quantized scales + Meta-Scañes (FP32)\n",
        "\n",
        "This compressed model can now be distributed and used!\n",
        "\n",
        "## Usage Phase (Reconstruction)\n",
        "\n",
        "Two-Step reconstruction:\n",
        "\n",
        "Meta-scales -> Scales -> Weights\n",
        "\n",
        "**Step 1**: Dequantize scales (Using meta-scales)\n",
        "-> You reconstruct weights by first turning the compress scale back into usuable scales using the meta-scales\n",
        "**Step 2**: Dequantize Weights (using re constructed scales)\n",
        "-> Using those reconstructed scales to de-quantize the actual weights.\n",
        "**Final**: Ready for computation\n",
        "\n",
        "### When to we quantize\n",
        "\n",
        "* Fine tuning\n",
        "\n",
        "Dequantize base weights for gradient computation (weights stay frozen)\n",
        "\n",
        "* Inference\n",
        "\n",
        "Dequantize weights for final predictions"
      ],
      "metadata": {
        "id": "zuQ1oJbQN-3Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vamos a hacer la \"contabilidad de bits\" exacta para que visualizar dónde está el ahorro. Es pura matemática de optimización.\n",
        "\n",
        "La clave es entender que en un modelo gigante, los Scaling Factors **(esas \"leyendas\" en Float32)** son tantos que empiezan a pesar mucho.\n",
        "\n",
        "Supongamos la configuración estándar de QLoRA: Bloques de 64 pesos.\n",
        "\n",
        "**1. Escenario A: Sin Double Quantization (Solo INT4)**\n",
        "\n",
        "Aquí comprimimos los pesos, pero dejamos los scaling factors en calidad original (32-bits).\n",
        "* **Los Pesos**: 1 bloque tiene 64 pesos de 4-bits.$$64 \\times 4 = 256 \\text{ bits}$$\n",
        "* **El Scaling Factor**: Necesitamos 1 número Float32 por bloque.$$1 \\times 32 = 32 \\text{ bits}$$\n",
        "* **Costo Promedio por Peso**:$$\\text{Overhead} = \\frac{32 \\text{ bits (scale)}}{64 \\text{ pesos}} = \\mathbf{0.5 \\text{ bits por peso}}$$\n",
        "\n",
        "**Conclusión A**: Además de los 4 bits del dato, estás gastando 0.5 bits extra por cada parámetro en \"metadata\".\n",
        "\n",
        "---\n",
        "\n",
        "**2. Escenario B: Con Double Quantization**\n",
        "\n",
        "Aquí aplicamos la recursividad: tomamos esos Scaling Factors (que eran Float32) y los **cuantizamos a 8-bits (FP8)**.\n",
        "\n",
        "Para hacer esto, agrupamos los Scaling Factors en bloques de 256 (un \"bloque de bloques\").\n",
        "\n",
        "* Los Pesos: Siguen igual (4 bits).\n",
        "* El Scaling Factor (Comprimido): Ahora cada bloque de 64 pesos tiene un scale de solo 8 bits.$$\\frac{8 \\text{ bits}}{64 \\text{ pesos}} = 0.125 \\text{ bits por peso}$$\n",
        "* El Meta-Scale (Nuevo): Necesitamos 1 Float32 para \"descomprimir\" el grupo de 256 scales.$$\\frac{32 \\text{ bits}}{256 \\times 64 \\text{ pesos}} = 0.0019 \\text{ bits por peso}$$(Es despreciable).\n",
        "* **Costo Promedio Total**:$$\\text{Overhead} = 0.125 + 0.002 \\approx \\mathbf{0.127 \\text{ bits por peso}}$$\n",
        "\n",
        "---\n",
        "\n",
        "**3. El Resultado Final (La Diferencia)**\n",
        "Vamos a comparar el \"impuesto\" de memoria (overhead) que pagas por mantener la precisión:\n",
        "\n",
        "| Método | Costo extra por Peso | Ahorro |\n",
        "| :--- | :---: | :---: |\n",
        "| Single Quantization | 0.5 bits | - |\n",
        "| Double Quantization | 0.127 bits | 0.373 |\n",
        "\n",
        "Puede parecer poco (0.37 bits), pero multiplícalo por un modelo grande:\n",
        "\n",
        "**Para un modelo Llama-65B (65 Billones de parámetros):**\n",
        "\n",
        "$$65,000,000,000 \\times 0.373 \\text{ bits} \\approx 24,245,000,000 \\text{ bits}$$$$\\approx \\mathbf{3 \\text{ GB de VRAM ahorrados}}$$\n",
        "\n",
        "**Resumen para tu bolsillo**\n",
        "\n",
        "Esos 3 GB extra que te ahorra la Double Quantization son la diferencia entre que el modelo quepa en una tarjeta gráfica de consumidor (como una RTX 3090 o 4090 de 24GB) o que tengas que alquilar un servidor industrial A100 mucho más caro.Es una optimización pequeña a nivel unitario, pero masiva a escala."
      ],
      "metadata": {
        "id": "qQxTFXy1Uv--"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating the Training Function Part 1 & 2\n",
        "\n",
        "We are gonna start creating our training function.\n",
        "\n",
        "`dataset = load_from_disk(args.dataset_path)`\n",
        "\n",
        "Loads a process dataset saved locally at the args.dataset_path, and this is our tokenized text dataset ready for casual language modelling.\n",
        "\n",
        "`load_in_4bit = True`\n",
        "\n",
        "Load the model in 4 bit precision instead of the full 16 or 32 bit precision. And this actually repleces the standard linear layer with `bnb.nn.Linear4bitLayer`, which is why we can look for these layer in `find_all_linear_names()`\n",
        "\n",
        "`bnb_4bit_quant_type = \"nf4\"`\n",
        "\n",
        "This specifies the quantization format to use for converting full precision weights into 4 bit values. nf4 stands for normal float 4 bit which is a custom 4 bit floating point format introduce by the bits&bytes library, and it mimics the distribution of normal floats values meaning it handle small and large number better than the standard INT4, so it improves quantization accuracy especially for transformer weights that follow a roughfly Gaussian.\n",
        "\n",
        "`bnb_4bit_compute_dtype = torch.bfloat16`\n",
        "\n",
        "This specifies the precision use for computation, example matrix multiplication after the weights have been dequantized from 4bits.\n",
        "Remeber our model weights are stored in 4bit, nf4, for memory saving, but before computing, for example the forward pass, they get dequantized for a higher presion type and this line tells the model to do all the math, example attention layer, layer norms, activation in BFloat16 precision.\n",
        "When the weights get de-quantized, it means they get reconstructed using the scale parameters.\n",
        "\n",
        "Esta línea es crítica. Le dice a la GPU: \"Guarda los datos en 4 bits para ahorrar espacio, pero cuando tengas que hacer multiplicaciones, descomprímelos a Bfloat16 para que el cálculo sea preciso, y luego vuelve a borrarlos\".\n",
        "\n",
        "\n",
        "`model = AutoModelForCasualLM.from_pretrained()`\n",
        "\n",
        "this loads a pre-trained casual language model that it is use for text generation. Casual LM means each token is predicted based on the previous ones so it is a decoder only.\n",
        "\n",
        "Aquí se descarga Mistral (o el modelo que elijas) y se aplica la configuración anterior. Al terminar esta línea, el modelo ya está en la VRAM ocupando solo ~24GB en lugar de 90GB.\n",
        "\n",
        "`use_cache = False if args.gradient_checkpointing else True`\n",
        "\n",
        "`gradient_checkpointing` funciona recalculando el pasado a propósito para ahorrar RAM. Son técnicas opuestas. Si activas el Checkpointing (para ahorrar memoria), estás obligado a apagar la Cache\n",
        "\n",
        "`device_map = \"auto\"`\n",
        "\n",
        "Automatically spread the model across available devices.\n",
        "\n",
        "`trainer.train()`\n",
        "\n",
        "`Trainer`: Es una clase de alto nivel de Hugging Face que abstrae el bucle complejo (Forward -> Loss -> Backward -> Optimizer Step).\n",
        "`trainer.train()`: Es el botón de encendido. Aquí empieza el bucle for que itera sobre tu dataset, calcula el error de las matrices $A$ y $B$, y las actualiza poco a poco.\n",
        "\n",
        "model = model.merge_and_unload()\n",
        "\n",
        "We are gonna combine the LoRA adapter weights with the frozen model weights into a single merge model. After merging the LoRA adapter layers are unloade from memory."
      ],
      "metadata": {
        "id": "K7YlUcDxnRd6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Resumen Visual del Flujo\n",
        "1. Entrada: Datos crudos del disco (load_from_disk).\n",
        "\n",
        "2. Preparación: Se carga el modelo comprimido en 4-bits (nf4) con doble cuantización.\n",
        "\n",
        "3. Modificación: Se le pegan los adaptadores LoRA.\n",
        "\n",
        "4. Acción: trainer.train() empieza a pasar datos.\n",
        "\n",
        "* Los datos viajan por el modelo de 4-bits (descomprimiéndose milisegundos a bf16).\n",
        "\n",
        "* El error se calcula.\n",
        "\n",
        "* Solo se actualizan los adaptadores.\n",
        "\n",
        "5. Salida: Al final, tendrás un modelo base intacto y unos adaptadores pequeños entrenados listos para guardar."
      ],
      "metadata": {
        "id": "Oy0Eec9Ga1ir"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def training_function(args):\n",
        "  set_seed(args.seed)\n",
        "\n",
        "  dataset = load_from_disk(args.dataset_path)\n",
        "\n",
        "  # Load the model from the hub with bnb congif\n",
        "  bnb_config = BitsAndBytesConfig(\n",
        "      load_in_4bit = True,\n",
        "      bnb_4bit_use_double_quant = True,\n",
        "      bnb_4bit_quant_type = \"nf4\",\n",
        "      bnb_4bit_compute_dtype = torch.bfloat16\n",
        "  )\n",
        "\n",
        "  model = AutoModelForCasualLM.from_pretrained(\n",
        "      args.model_id,\n",
        "      use_cache = False if args.gradient_checkpointing else True, # we are using gradient checkpointing so we must disable the cache to save memory\n",
        "      device_map = \"auto\",\n",
        "      quantization_config = bnb_config,\n",
        "      force_download=True\n",
        "  )\n",
        "\n",
        "  model = create_peft_model(\n",
        "      model, gradient_checkpointing=args.gradient_checkpointing,\n",
        "      bf16=args.bf16\n",
        "  )\n",
        "\n",
        "  # define the directory qhere the modeland the logs will be saved\n",
        "  output_dir = \"/tmp/mixtral\"\n",
        "\n",
        "  # define the training args in the HuggingFace training arguments\n",
        "  training_args = TrainingArguments(\n",
        "      output_dir = output_dir,\n",
        "      per_device_train_batch_size = args.per_device_train_batch_size,\n",
        "      bf16 = args.bf16,\n",
        "      learning_rate = args.lr,\n",
        "      num_train_epochs = args.epochs,\n",
        "      gradient_checkpointing = args.gradient_checkpointing,\n",
        "      logging_dir = f\"{output_dir}/logs\",\n",
        "      logging_strategy = \"steps\",\n",
        "      logging_steps = 10,\n",
        "      save_strategy = \"no\"\n",
        "  )\n",
        "\n",
        "  trainer = Trainer(\n",
        "      model = model,\n",
        "      args = training_args,\n",
        "      train_dataset = dataset,\n",
        "      data_collator = default_data_collator\n",
        "  )\n",
        "\n",
        "  trainer.train()\n",
        "\n",
        "  sagemaker_save_dir = \"/opt/ml/model/\"\n",
        "\n",
        "  if args.merge_weights:\n",
        "    # if LoRA is enable we are gonna save the current fine tune model with the LoRA adapters separetly to a loacal folder output directory\n",
        "    # we save the model because it is still in NF4 format with separete LoRA adapters\n",
        "    # this are in INT4 and we cant merge them\n",
        "    # Mergin LoRA into an INT4 model isnt supported, so that is why we save it\n",
        "    trainer.model.save_pretrained(output_dir, safe_serialization=False)\n",
        "    # Remeber: after it is done with the fine tuning it is in int4 format\n",
        "\n",
        "\n",
        "    # we deleted everything to some space because it is already save\n",
        "    del model\n",
        "    del trainer\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    from peft import AutoPeftModelForCasualLM\n",
        "\n",
        "    # then we reload it, and this is the key part\n",
        "    # we loaded back in float16, because merging LoRA into int4 model isnt supported\n",
        "    # it needs higher precision\n",
        "    # So we load it back in with fp16\n",
        "    model = AutoPeftModelForCasualLM(\n",
        "        output_dir,\n",
        "        low_cpu_mem_usage = True,\n",
        "        torch_dtype = torch.float16\n",
        "    )\n",
        "\n",
        "    # Once we have loaded, in a float16 format, then what we can do is\n",
        "    # call the merge_and_unload(), which combines the LoRA weights into\n",
        "    # the base model and this result is a float16 model\n",
        "    # which can e readily used for inference without needing adopters\n",
        "    model = model.merge_and_unload()\n",
        "\n",
        "    model.save_pretrained(\n",
        "        sagemaker_save_dir, safe_serialization = True, max_shard_size = '2GB'\n",
        "    )\n",
        "  else:\n",
        "    trainer.model_save_pretrained(\n",
        "        sagemaker_save_dir, safe_serialization = True\n",
        "    )\n",
        "\n",
        "  tokenaizer = AutoTokenizer.from_pretrained(args.model_id)\n",
        "  tokenaizer.save_pretrained(sagemaker_save_dir)"
      ],
      "metadata": {
        "id": "TnBpfwO0nZtk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Finishing our Sagemaker Script\n",
        "def main():\n",
        "  args = parse_arge()\n",
        "  training_function(args)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  main()"
      ],
      "metadata": {
        "id": "ha1BNb3BtaN1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}